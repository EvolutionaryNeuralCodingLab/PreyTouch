"""
This module is responsible for the offline parsing and organization of the detections data, and for loading the
data into the memory for analysis in a notebook. The module's functions mostly operate with Pandas DataFrames.

The first part of the module is responsible for analyzing new trials and saving the detections and other related data
to files.
The second part is responsible for collecting the detections data from different trials, possibly joining it
with other sources of data, and loading it as single dataframe into memory, to be analyzed in a Jupyter notebook.
The loading into memory code is not scalable, and could fit a dataframe as large the memory allows, in addition
to the sequences tensors generated by the function in train_eval.py. The project document lists some possible
solutions to this issue.
"""

import pandas as pd
import numpy as np
import re
import os
import cv2 as cv
import pickle
from tqdm.auto import tqdm
import json
from pathlib import Path

from Prediction.detector import nearest_detection
import Prediction.calibration as calib

# various folder and file names constants

REALTIME_ID = "19506468"

# depending on from where the program is run, add ../..
EXPERIMENTS_ROOT = Path("../../Pogona_Pursuit/Arena/experiments/")
OUTPUT_ROOT = Path("../../Pogona_Pursuit/Arena/output/")
CALIBRATIONS_ROOT = Path("../../Pogona_Pursuit/Arena/calibration")

RT_DATA_FOLDER = "rt_analysis"
VIDEOS_FOLDER = "videos"

HEAD_CROPS_FN = "head_crops.p"
RT_DF_FN = "rt.csv"
RT_TRNS_DF_FN = "rt_trns.csv"
HOMOGRAPHY_IM_FN = "homography.jpg"
VID_STATS_FN = "vid_stats.json"

TIMESTAMPS_FN = "timestamps/" + REALTIME_ID + ".csv"
TOUCHES_FN = "screen_touches.csv"
BUG_TRAJ_FN = "bug_trajectory.csv"

# various folders and terms in the experiments folder to exclude from the analysis and data collection
EXCLUDE_TERMS = [
    "initial",
    "delete",
    "fps",
    "vegetables",
    "test-no-streaming",
    "sleepy",
    "predictor",
    "forecasts",
    "feeding3_20200902-122338",  # false positive in homography
    "feeding3_20200902-122611",  # same
    "cockroach_circle_20200902T121652",  # same
    "cockroach_20200907T152020",  # carpet hindered calibration
    "cockroach_20200907T145302",  # same
    "circle_20200907T145105",  # same
    "feeding3_20200902-142400",  # alpha 0.3 probably caused a corner black hole
    "202007",
    "20200902",
    "20201108",
    "20201109",
    "20201110",
    "20201111",
    "20201115",
    "20201118",
    "20201123",
    "20201125",
]

# same in the output folder
OUTPUT_TERMS = ["feeding"]

# DEFAULT_HOMOGRAPHY_JSON = "homographies.json"
DEFAULT_HOMOGRAPHY_JSON = "Prediction/homographies.json"

# --------- Helper Functions ---------


class DatasetException(Exception):
    pass


def find_rt_video_path(videos_dir: Path) -> Path:
    """
    Find the realtime camera video file relative to the directory containing the videos and
    return its Path.
    """
    old_path = videos_dir / (REALTIME_ID + ".avi")
    if not old_path.exists():
        vid_file = list(
            filter(lambda f: f.startswith("realtime"), os.listdir(videos_dir))
        )
        if vid_file == []:
            return None
        else:
            return videos_dir / vid_file[0]

    else:
        return old_path


def trial_name_to_tuple(trial_name):
    spl = trial_name.split("/")
    experiment = "/".join(spl[:-1])
    trial = spl[-1] if spl[-1] != "None" else None

    return experiment, trial


def trial_tuple_to_name(trial_tuple):
    return "/".join(trial_tuple)


def trial_path_to_name(
    trial_path: Path, output_root=OUTPUT_ROOT, experiments_root=EXPERIMENTS_ROOT
):
    if trial_path.parent == OUTPUT_ROOT:
        return f"{trial_path.name}/None"
    elif trial_path.parent.parent == EXPERIMENTS_ROOT:
        return "/".join(trial_path.parts[-2:])
    else:
        return None


def get_experiment_trial_videos_dir(trial_path: Path) -> Path:
    video_dir = trial_path / VIDEOS_FOLDER
    if not video_dir.exists():
        return None

    ls = list(filter(lambda f: not f.startswith("."), os.listdir(video_dir)))
    if len(ls) == 1 and (video_dir / ls[0]).is_dir():
        # old directory structure
        return video_dir / ls[0]
    else:
        return video_dir


def get_trial_videos_dir(trial) -> Path:
    """Return a Path pointing to the directory that contains videos for this trial."""
    if type(trial) is str:
        trial = trial_name_to_tuple(trial)

    trial_path = get_trial_path(trial)

    if trial[1] is not None:
        return get_experiment_trial_videos_dir(trial_path)
    else:
        # output trial
        return trial_path


def get_trial_video_path(trial) -> Path:
    """Return a Path pointing to the video file of the realtime camera for this trial."""
    videos_dir = get_trial_videos_dir(trial)
    return find_rt_video_path(videos_dir)


def get_trial_path(trial) -> Path:
    """Return a Path pointing to the directory of this trial."""
    if type(trial) is str:
        trial = trial_name_to_tuple(trial)

    if trial[1] is not None:
        # experiment trial
        return EXPERIMENTS_ROOT / trial[0] / trial[1]
    else:
        # output trial
        return OUTPUT_ROOT / trial[0]


def get_homography_for_trial(trial):
    trial_path = get_trial_path(trial)
    json_path = trial_path / RT_DATA_FOLDER / VID_STATS_FN

    with open(json_path, "r") as f:
        vid_stats = json.load(f)

    return np.array(vid_stats["homography"])


def get_transformed_data_path(trial) -> Path:
    p = get_trial_path(trial) / RT_DATA_FOLDER / RT_TRNS_DF_FN
    if p.exists():
        return p


def get_date_from_path(path: Path):
    """
    :param path: path to experiment or trial folder
    :return: date that contained in the path string in YYYYMMDD-HHMMSS format
    """
    to_search = path.name
    matches = re.findall(r"\d{8}T\d{6}", to_search)
    if len(matches) != 0:
        return pd.to_datetime(matches[-1])
    else:
        matches = re.findall(r"\d{8}-\d{6}", to_search)
        if len(matches) != 0:
            return pd.to_datetime(matches[-1])
        else:
            return get_date_from_path(path.parent)


# -------- Data Analysis ---------


def get_cropped_head(img, detection, orig_dim):
    """
    Returns the flattened cropped head

    :param img: the resized numpy image that was detector run on last (usually 416X416)
    :param detection: the 5-array (x1,y1,x2,y2,prob) that includes the detection
    :param orig_dim: tuple, the dimensions of the original image, before resizing to YOLO dimensions
    :return: the cropped resized flattened numpy image array (copy)
    """
    src_x1, src_y1 = detection[0], detection[1]
    src_x2, src_y2 = detection[2], detection[3]

    img_x = img.shape[1]
    img_y = img.shape[0]
    orig_x = orig_dim[1]
    orig_y = orig_dim[0]  # open_cv shape order - (Y,X) not (X,Y)

    x_scale = img_x / orig_x
    y_scale = img_y / orig_y

    dst_x1, dst_y1 = round(src_x1 * x_scale), round(src_y1 * y_scale)
    dst_x2, dst_y2 = round(src_x2 * x_scale), round(src_y2 * y_scale)

    dst_x1, dst_y1 = int(dst_x1), int(dst_y1)
    dst_x2, dst_y2 = int(dst_x2), int(dst_y2)

    dst_x1, dst_x2 = max(0, dst_x1), max(0, dst_x2)
    dst_y1, dst_y2 = max(0, dst_y1), max(0, dst_y2)

    dst_x1, dst_x2 = min(img_x, dst_x1), min(img_x, dst_x2)
    dst_y1, dst_y2 = min(img_y, dst_y1), min(img_y, dst_y2)

    cropped_head = img[dst_y1:dst_y2, dst_x1:dst_x2].copy()

    cropped_head = cv.cvtColor(cropped_head, cv.COLOR_BGR2GRAY)
    cropped_head = 255 - cropped_head

    return cropped_head


def analyze_single_video(
    video_path, detector, start_frame=0, num_frames=None,
):
    """
    Analyze a single video doing the bounding box inference, and returning a 2d array of detections
    also saving the flattened resized cropped head images in 2d array for other uses

    :param video_path: path for the video file
    :param detector: subclass implementing the Detector object
    :param start_frame: int, frame to start from in the video
    :param num_frames: int, number of frames to analyze from the video
    :return: 2D numpy array of detections
    """

    vcap = cv.VideoCapture(str(video_path))

    if start_frame != 0:
        vcap.set(cv.CAP_PROP_POS_FRAMES, start_frame)

    if num_frames is None:
        num_frames = int(vcap.get(cv.CAP_PROP_FRAME_COUNT)) - start_frame
        if num_frames == 0:
            raise DatasetException(f"No Frames found in video {video_path}")

    width = int(vcap.get(3))
    height = int(vcap.get(4))

    # frames_data: x1, y1, x2, y2, confidence, num_boxes
    frames_data = np.empty((num_frames, 6))
    frames_data[:] = np.nan

    head_crops = []

    vcap.set(cv.CAP_PROP_POS_FRAMES, start_frame)

    # inference on each frame
    for frameCounter in tqdm(range(num_frames)):
        ret, frame = vcap.read()

        if not ret:
            raise DatasetException("Error reading frame.")

        detections = detector.detect_image(frame)

        if detections is not None:
            if frameCounter > 0:
                prev = frames_data[frameCounter - 1][:2]
                detection = nearest_detection(detections, prev)
            else:
                detection = detections[0]

            # insert new detection in matrix, each row is x1, y1, x2, y2, confidence.
            frames_data[frameCounter][0:5] = detection
            frames_data[frameCounter][5] = detections.shape[0]

            cropped_head = get_cropped_head(
                detector.curr_img, detection, (height, width)
            )

            # append cropped head to list
            head_crops.append(cropped_head)

        else:
            # if no there's no detection, append None element so the order will be kept
            head_crops.append(None)
            frames_data[frameCounter][5] = 0

    vcap.release()

    return frames_data, head_crops, width, height


def find_last_homography(experiment_path: Path):
    """
    Find the last homography relative to date of an experiment by finding the calibration date with smallest
    positive timedelta relative to video date

    :param path: path to the trial folder
    :return: homography numpy array, json file path
    """
    experiment_date = get_date_from_path(experiment_path)
    calibration_paths = np.array(list(CALIBRATIONS_ROOT.glob("*")))
    calibration_dates = pd.Series(
        [get_date_from_path(calib_path) for calib_path in calibration_paths]
    )
    tiled_video_date = pd.Series([experiment_date] * calibration_dates.shape[0])
    date_diffs = tiled_video_date - calibration_dates
    dates_before = date_diffs >= pd.Timedelta(0)
    if len(date_diffs[dates_before]) == 0:
        return None, None

    last_date_idx = (date_diffs[dates_before]).argmin()
    last_calib_path = calibration_paths[dates_before.to_numpy()][last_date_idx]

    with open(last_calib_path, "r") as fp:
        homog_dict = json.load(fp)

    return np.array(homog_dict["homography"]), last_calib_path


def align_bug_trajectory(bdf, tdf, max_delta_ms=20):
    """
    Align bug trajectory data to video frame timestamps.
    Compare timestamps from both dataframes and finds the closest bug trajectory event
    before a frame timestamp.

    :param bdf: Bug trajectory pandas dataframe read from a bug_trajectory.csv file.
    :param tdf: Video frame timestamps pandas dataframe read from a timestamps.csv file.
    :param max_delta_ms: The maximum time delta between a bug position timestamp and a frame timestamp for alignment.

    :return: pandas dataframe with bug_x, bug_y, and bug_ts columns (x, y position and original bug timestamp 
             respectively). Row k corresponds with the kth frame in the video.
    """
    frame_count = tdf.shape[0]
    df = pd.DataFrame(columns=["bug_x", "bug_y", "bug_ts"])
    df["bug_x"] = pd.Series([np.nan] * frame_count, dtype="float")
    df["bug_y"] = pd.Series([np.nan] * frame_count, dtype="float")
    df["bug_ts"] = pd.Series([None] * frame_count, dtype=tdf.index.dtype)

    first_diff = bdf.index[0] - tdf.index[0]

    if first_diff >= pd.Timedelta(0):
        first_frame = tdf.index.get_loc(bdf.index[0], method="pad") + 1
        first_bug = 0
    else:
        first_frame = 0
        first_bug = bdf.index.get_loc(tdf.index[0], method="pad")

    for i, ts in enumerate(tdf.index[first_frame:]):
        if i == 0:
            cur_bug = first_bug
        else:
            cur_bug = (
                bdf.index[cur_bug:].get_loc(tdf.index[i + first_frame], method="pad")
                + cur_bug
            )

        if (tdf.index[i + first_frame] - bdf.index[cur_bug]) >= pd.Timedelta(
            max_delta_ms, "ms"
        ):
            continue

        df.iloc[i + first_frame, df.columns.get_loc("bug_x")] = bdf.iloc[
            cur_bug, bdf.columns.get_loc("x")
        ]
        df.iloc[i + first_frame, df.columns.get_loc("bug_y")] = bdf.iloc[
            cur_bug, bdf.columns.get_loc("y")
        ]
        df.iloc[i + first_frame, df.columns.get_loc("bug_ts")] = bdf.index[cur_bug]

        if cur_bug == len(bdf.index) - 1:
            # reached end of bug trajectory data.
            break

    return df


def align_touches(touches_df, ts_df):
    """
    Align the the screen touching data to the detections data, by aligning the data according to closest timestamps
    changes dataframe inplace.

    last fix - 31/10. All files have only 'time' column. - check if touch timestamp data is tz aware:
    if not, localize and shift to 'Israel' tz.
    This is probably still a buggy and incorrect solution, should be fixed in the future

    :param df: dataframe with one row per frame
    :param temp_touches: screen touches dataframe
    """
    if "is_hit" not in touches_df.columns:
        touches_df.insert(
            loc=len(touches_df.columns) - 1,
            column="is_hit",
            value=pd.Series([None] * touches_df.shape[0], dtype="boolean"),
        )

    frame_count = ts_df.shape[0]
    df = pd.DataFrame(
        columns=[
            "touch_x",
            "touch_y",
            "bug_x",
            "bug_y",
            "is_touch",
            "is_hit",
            "touch_ts",
        ]
    )
    df.touch_x = pd.Series([np.nan] * frame_count, dtype="float")
    df.touch_y = pd.Series([np.nan] * frame_count, dtype="float")
    df.bug_x = pd.Series([np.nan] * frame_count, dtype="float")
    df.bug_y = pd.Series([np.nan] * frame_count, dtype="float")
    df.is_touch = pd.Series([False] * frame_count, dtype="boolean")
    df.is_hit = pd.Series([False] * frame_count, dtype="boolean")
    df.touch_ts = pd.Series([None] * frame_count, dtype=touches_df.index.dtype)

    # for timestamp of each touch, get frame with closest timestamp
    for i, ts in enumerate(touches_df.index):

        frame_argmin = np.argmin(np.abs((ts_df.index - ts).total_seconds().values))

        col_inds = [
            df.columns.get_loc(col)
            for col in ["touch_x", "touch_y", "bug_x", "bug_y", "is_hit"]
        ]
        to_set = [
            touches_df.columns.get_loc(col)
            for col in ["x", "y", "bug_x", "bug_y", "is_hit"]
        ]

        # setting values for part of row
        df.iloc[frame_argmin, col_inds] = touches_df.iloc[i, to_set].values
        df.iloc[frame_argmin, df.columns.get_loc("is_touch")] = True
        df.iloc[frame_argmin, df.columns.get_loc("touch_ts")] = touches_df.index[i]

    return df


def analyze_rt_data(trial_path: Path, videos_dir: Path, detector):
    """
    Analyze a single video and save data to the realtime directory:
    parse detections and other metadata into a single trial dict, and save data to file

    :param trial_path: path to the trial folder (where the rt_data folder will be created).
    :param videos_path: path to the folder containing the video.
    :param detector: a bbox detector for the pogona head.
    """

    vid_path = find_rt_video_path(videos_dir)
    timestamp_path = videos_dir / TIMESTAMPS_FN
    touches_path = trial_path / TOUCHES_FN
    bug_traj_path = trial_path / BUG_TRAJ_FN

    rt_dir = trial_path / RT_DATA_FOLDER
    head_crops_path = rt_dir / HEAD_CROPS_FN
    rt_df_path = rt_dir / RT_DF_FN
    json_path = rt_dir / VID_STATS_FN

    try:
        # analyze video with detector
        (detections, head_crops, vid_width, vid_height) = analyze_single_video(
            video_path=vid_path, detector=detector
        )
    except DatasetException:
        print(f"Error reading video file: {vid_path}")
        return

    det_df = pd.DataFrame(
        data=detections, columns=["x1", "y1", "x2", "y2", "conf", "num_bbox"]
    )

    # read frame timestamps
    timestamp_df = pd.read_csv(timestamp_path, index_col=1, parse_dates=True)
    if timestamp_df.index.tz is None:
        timestamp_df.index = timestamp_df.index.tz_localize("UTC")
    timestamp_df.index = timestamp_df.index.tz_convert("Israel")

    concat_dfs = [det_df]

    # read touches and align with camera frames
    if touches_path.exists():
        touches_df = pd.read_csv(touches_path, index_col="time", parse_dates=True)

        if touches_df.index.tz is None:
            touches_df.index = touches_df.index.tz_localize("UTC")
        touches_df.index = touches_df.index.tz_convert("Israel")

        aligned_touches_df = align_touches(touches_df, timestamp_df)
        if bug_traj_path.exists():
            concat_dfs.append(aligned_touches_df.drop(["bug_x", "bug_y"], axis=1))
        else:
            concat_dfs.append(aligned_touches_df)

    # read bug trajectory and align with camera frames
    if bug_traj_path.exists():
        bdf = pd.read_csv(bug_traj_path, index_col=1, parse_dates=True)
        bdf = bdf[~bdf.index.duplicated(keep="first")]
        if bdf.index.dtype == int:
            bdf.index = pd.to_datetime(bdf.index, unit="ms")
        if bdf.index.tz is None:
            bdf.index = bdf.index.tz_localize("UTC")

        bdf.index = bdf.index.tz_convert("Israel")
        aligned_bug_traj_df = align_bug_trajectory(bdf, timestamp_df)

        concat_dfs.append(aligned_bug_traj_df)

    df = pd.concat(concat_dfs, axis=1)
    df.insert(0, "frame_ts", timestamp_df.index)

    # Write data to files

    if not rt_dir.exists():
        rt_dir.mkdir()

    df.to_csv(rt_df_path)

    # pickle head crops
    with open(head_crops_path, "wb") as fp:
        pickle.dump(head_crops, fp)

    # find last homography relative to video date
    experiment_path = (
        trial_path.parent if trial_path.name.startswith("trial") else trial_path
    )
    homography, calib_path = find_last_homography(experiment_path)

    with open(json_path, "w") as fp:
        vid_stats = {
            "width": vid_width,
            "height": vid_height,
        }

        if homography is not None:
            vid_stats["homography"] = homography.tolist()
            vid_stats["homography_src_file"] = str(calib_path)

        json.dump(vid_stats, fp)


def find_analysis_paths(
    output_root=OUTPUT_ROOT,
    experiments_root=EXPERIMENTS_ROOT,
    output_terms=OUTPUT_TERMS,
):
    """
    Return all paths that contain a video from the realtime camera, a timestamp file,
    that do not already contain an rt_data folder and that don't contain an excluding term in their name.

    :param output_root: path to the output directory (general video recordings)
    :param experiments_root: path to the experiments directory
    :param output_terms: List of terms that indicate that analysis is needed
    :return: list of Path tuples (trial_path, videos_path) for each matching experiment trial.
    """
    output_paths = []
    for term in output_terms:
        output_paths += list(output_root.glob(f"*{term}*"))

    trial_paths = list(experiments_root.glob("*/trial*"))

    trial_video_paths = [
        get_experiment_trial_videos_dir(trial_path) for trial_path in trial_paths
    ]
    all_video_paths = output_paths + trial_video_paths
    all_trial_paths = output_paths + trial_paths

    def path_filter(paths):
        trial_path, videos_path = paths

        if videos_path is None or trial_path is None:
            return False
        if any([dont in str(trial_path) for dont in EXCLUDE_TERMS]):
            return False
        if os.path.exists(os.path.join(trial_path, RT_DATA_FOLDER)):
            return False
        if find_rt_video_path(videos_path) is None:
            return False
        if not os.path.exists(
            os.path.join(videos_path, "timestamps", REALTIME_ID + ".csv")
        ):
            return False
        return True

    return list(filter(path_filter, zip(all_trial_paths, all_video_paths)))


def analyze_new_data(
    detector, output_root=OUTPUT_ROOT, experiments_root=EXPERIMENTS_ROOT
):
    """
    Get all new trials from output and experiment folders, and analyze them. A function to be called
    from console or from a notebook.

    :param detector: detector object
    :param output_root: root to output folders
    :param experiments_root: root to experiments folder
    :return: No return value, saves files to disk
    """
    paths = find_analysis_paths(output_root, experiments_root)

    for trial_path, videos_path in paths:
        print(f"Analyzing {trial_path}:")
        analyze_rt_data(trial_path, videos_path, detector)


def save_transformed_data(trial_paths: Path):
    """
    Read previously generated rt dataframes and undistort and transform them according to
    the default undistortion matrices and the homography matrix that is stored in each trials
    vid_stats.json file. The transformed data frame is saved to the same folder as a csv file.

    :param trial_paths: A list of trial Path objects
    """
    homography_column_pairs = [("x1", "y1"), ("x2", "y2")]

    for trial_path in tqdm(trial_paths):
        rt_dir = trial_path / RT_DATA_FOLDER
        rt_path = rt_dir / RT_DF_FN
        rt_trns_path = rt_dir / RT_TRNS_DF_FN
        vid_stats_path = rt_dir / VID_STATS_FN

        if not vid_stats_path.exists():
            print("vid_stats doesn't exist, skipping:", trial_path)
            continue

        with open(vid_stats_path, "r") as f:
            vid_stats = json.load(f)

        if vid_stats["width"] != 1440 or vid_stats["height"] != 1080:
            print("Wrong video dims, skipping:", trial_path)
            continue

        rt_df = pd.read_csv(rt_path, index_col=0)
        rt_trns_df = transform_df(rt_df, homography_column_pairs, vid_stats)
        rt_trns_df.to_csv(rt_trns_path)
        print(f"Saved transformed data to {rt_trns_path}")


""" --------------- Data Selection Functions --------------- """


def select_analyzed_trials_paths(
    output_root: Path = OUTPUT_ROOT,
    experiments_root: Path = EXPERIMENTS_ROOT,
    output_terms=OUTPUT_TERMS,
):
    """
    Find and return all analyzed trials paths under the supplied root directories.
    
    :param output_root: Base output trials directory path.
    :param experiments_root: Base experiment trials directory path.
    :param output_terms: List of strings that should appear in an output trial path to include it.
    """
    output_paths = []
    for term in output_terms:
        output_paths += list(output_root.glob(f"*{term}*"))

    trial_paths = list(experiments_root.glob("*/trial*"))
    all_trial_paths = output_paths + trial_paths

    return list(filter(lambda p: (p / RT_DATA_FOLDER).exists(), all_trial_paths))


def load_trial_data(
    trial_names, experiments_root=EXPERIMENTS_ROOT, output_root=OUTPUT_ROOT
):
    """
    Load and merge trial data from a number of trials.

    :param trial_names: List of trial names that will be loaded and merged.
    :return: Unified pandas dataframe containing all data indexed by trial name.
    """
    rt_paths = [get_transformed_data_path(t) for t in trial_names]
    dfs = []
    for p, name in tqdm(zip(rt_paths, trial_names), total=len(trial_names)):
        if p is not None:
            df = pd.read_csv(p)
            df.index = [name] * df.shape[0]
            dfs.append(df)

    unified_df = pd.concat(dfs)
    unified_df.index = pd.CategoricalIndex(unified_df.index)

    if "is_touch" in unified_df.columns:
        unified_df.is_touch = unified_df.is_touch.fillna(False)
    if "is_hit" in unified_df.columns:
        unified_df.is_hit = unified_df.is_hit.fillna(False)

    print(
        f"Loaded {len(dfs)} trials. {len([p for p in rt_paths if p is None])} were not loaded."
    )
    return unified_df


def parse_exper_log(exper):
    """
    Parse the log file of an experiment
    Possible to use yaml parser instead of this function, beside the lists which are not written
    to file correctly

    :param exper: file name to anaalyze
    :return: dictionary with the required parameters
    """

    with open(os.path.join(exper, "experiment.log"), "r") as f:
        exp_log = f.read()

    name = re.search(r"experiment_name: (.*)", exp_log)
    animal_id = re.search(r"animal_id: (\d+)\n", exp_log)
    num_trials = re.search(r"num_trials: (\d+)\n", exp_log)
    bug_type = re.search(r"bug_type: (.*)", exp_log)
    bug_speed = re.search(r"bug_speed: (\d+)\n", exp_log)
    mov_type = re.search(r"movement_type: (.*)", exp_log)

    d = dict()

    if name is not None:
        d["name"] = name.group(1)
    if animal_id is not None:
        d["animal_id"] = int(animal_id.group(1))
    if num_trials is not None:
        d["num_trials"] = int(num_trials.group(1))
    if bug_type is not None:
        d["bug_type"] = bug_type.group(1)
    if bug_speed is not None:
        d["bug_speed"] = int(bug_speed.group(1))
    if mov_type is not None:
        d["mov_type"] = mov_type.group(1)

    return d


def transform_df(df, cols, vid_stats):
    """
    Applies the  lens undistortion and homography transformation according to pairs of columns

    :param df: panads dataframe to correct
    :param cols: iterable of pairs of columns (x,y) to correct
    :param vid_stats: dictionary containing the homography
    :return: the corrected dataframe
    """
    if vid_stats["homography"] is not None:
        homography = np.array(vid_stats["homography"])
    else:
        with open(DEFAULT_HOMOGRAPHY_JSON, "r") as fp:
            homography_dict = json.load(fp)
        homography = np.array(homography_dict["new_h"])

    if "undist_alpha" in vid_stats:
        alpha = vid_stats["undist_alpha"]
    else:
        alpha = 0

    df = calib.undistort_data(
        df, vid_stats["width"], vid_stats["height"], cols, alpha=alpha
    )

    df = calib.transform_data(df, homography, cols)

    return df
