{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "- decide regarding the head stuff\n",
    "- add explanations for analyze_new_data\n",
    "- maybe add something else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/app/Pogona_realtime/Arena')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "import imp\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import imp\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy import stats\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "from Prediction import dataset\n",
    "from Prediction import predictor\n",
    "from Prediction import detector\n",
    "from Prediction.detector import Detector_v4, Detector_v3\n",
    "from Prediction import visualize\n",
    "from Prediction import calibration as calib\n",
    "from Prediction.kalman_predict import KalmanPredictor\n",
    "from Prediction.predictor import HitPredictor\n",
    "from Prediction.visualize import process_video, get_correction_fn, offline_predictor_visualizer\n",
    "from Prediction import seq2seq_predict\n",
    "from Prediction import train_eval\n",
    "\n",
    "WEIGHTS_PATH = 'Prediction/Yolo4/yolo4_gs_best_2306.weights'\n",
    "CFG_PATH = 'Prediction/Yolo4/yolo4_2306.cfg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize YOLOv4 detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detector initiated successfully\n"
     ]
    }
   ],
   "source": [
    "det = Detector_v4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze single trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.analyze_rt_data('../../Pogona_Pursuit/Arena/output/feeding_4_20200830-125905', det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze new trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.analyze_new_data(det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental: Convolutional cropped head encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropped Head images dataset and dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detections data pipeline:\n",
    "- detections.csv -> distortion and homography -> unified dataframe -> pytorch iterable dataset ->\n",
    "- split each trial to sequences in trial_to_samples (skips sequences with nan - original indexing breaks) ->\n",
    "- create train and test dataloaders, that returns shuffeled batches of sequences.\n",
    "\n",
    "Issues with cropped head files:\n",
    "- Memory issues: in contrast to detections data, not possible to load entire cropped heads data, from hundreds of trials, to memory.\n",
    "- Distorted and not transformed - we can pass on the distortion, but the homography is important. Maybe only rotate\n",
    "- Resizing and arranging in PyTorch tensors - possibly the easiest way.\n",
    "- None entries, aligining with detections indices.\n",
    "- Currently in a single pickle file, alternative is saving in different \n",
    "\n",
    "Options of arranging cropped head data and join on detections data: \n",
    "New dataset structure, options. currently, TrajectoriesData dataset has 3D tensors - (# sequence, # index in sequence, # xyxy): \n",
    "* __Images in memory__: It's possible to create a new dataset subclass, where it's passed X,Y and another 4d tensor, \"X_Images\". This tensor could be created by the trial_to_samples function. __Main problem: a single detection's image could be in at most 20 different sequences, thus duplicating the image in memory. Will probably get too heavy, even if the original data is in realtively reasonable size__\n",
    "* __Paths and alternative \\_\\_getitem\\_\\_ implementation__: each single sequence will have an array of paths for the images in that sequence, that will be returned by trial_to_samples. If X is a 3d tensor, then X_paths is a 2D tensor, each row containing either None or the path for the file. In each call to getitem, iterate over the paths and build a 3d tensor, an array of 2d images. Need to save in different files to work. It seems that's the way to do it... \"One way of handling this is to split the file into a bunch of smaller files each containing one line of the original, then maintain a list of the paths of these small files and in _getitem_ read the file corresponding to the specified index. _This is how people mostly work with image data, where they have a bunch of images located in a directory_\" from https://medium.com/swlh/how-to-use-pytorch-dataloaders-to-work-with-enormously-large-text-files-bbd672e955a0. Also here: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "* Alternatively, we could create new files for each trial, seperate from the dataframe - that natively include both the detections data and the image data, thus making it easier to organize the indices.\n",
    "\n",
    "* __IterableDataset__: The defualt utils.dataset is a Map Dataset, which supports in memory structures with indexing (or some getitem implementation like the \"paths\" one). The IterableDataset is supposed to work with data streams (databases, remote servers, very large files, etc.). Doesn't seem to fit our case, becuase we need to \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Required code changes for small amount of data (without reformatting entire data):__\n",
    "* Write function to trnasform a list of uneven images to a 3d tensor.\n",
    "* In trial_to_samples, accept a tensor of images of trial to jointly create a tuple of detections sequences tensor and image sequences tensor\n",
    "* In TrajectoriesDataset, add images sequences tensor, where getitem returns a sequence of images along with the detections.\n",
    "* In train_eval function, change to get image tensor and pass it to a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Prediction.dataset' from '/app/Pogona_realtime/Arena/Prediction/dataset.py'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(train_eval)\n",
    "imp.reload(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 trials loaded\n"
     ]
    }
   ],
   "source": [
    "df = dataset.collect_data(data_sources={'detections': True, 'timestamps': True, 'dlc': False, 'touches': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = dataset.select_paths(data_sources={'detections': True, 'timestamps': True, 'dlc': False, 'touches': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rot_angle(homography):\n",
    "    return - math.atan2(homography[0,1], homography[0,0]) * 180 / math.pi\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv.INTER_LANCZOS4)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_data_with_heads_that_are_rotated(trial_tuple):\n",
    "    trial_p = glob.glob(os.path.split(all_paths[trial_tuple]['detections'])[0]+'/*.p')[0]\n",
    "\n",
    "    with open(all_paths[trial_tuple]['vid_stats'], 'r') as fp:\n",
    "        vid_stats = json.load(fp)\n",
    "    \n",
    "    if vid_stats['homography'] is None:\n",
    "        with open(dataset.DEFAULT_HOMOGRAPHY_JSON, 'r') as fp:\n",
    "            h = np.array(json.load(fp)['new_h'])\n",
    "    else:\n",
    "        h = np.array(vid_stats['homography']) \n",
    "    rot_angle = get_rot_angle(h)\n",
    "\n",
    "    with open(trial_p, 'rb') as fp:\n",
    "        head_list = pickle.load(fp)\n",
    "    \n",
    "    rotated_head_list = [rotate_image(255-im, rot_angle) if im is not None else None for im in head_list]\n",
    "    trial_df = df.loc[\"_\".join((trial_tuple[0], str(trial_tuple[1])))]\n",
    "    \n",
    "    return trial_df, rotated_head_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials = df.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = train_eval.create_train_val_test_splits(all_trials, [0.8, 0.2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('line_20200803T082002', 'trial1')\n",
      "('worm_circle_20200830T122241', 'trial1')\n",
      "('line_20200803T122506', 'trial1')\n",
      "('circle_20200803T084529', 'trial1')\n",
      "('cockroach_circle_20200830T123508', 'trial1')\n",
      "('feeding_4_20200830-125531', None)\n"
     ]
    }
   ],
   "source": [
    "input_labels = ['x1', 'y1', 'x2', 'y2']\n",
    "output_labels = ['x1', 'y1', 'x2', 'y2']\n",
    "input_dim = len(input_labels)\n",
    "output_dim = len(output_labels)\n",
    "\n",
    "inp_seq_len = 20\n",
    "out_seq_len = 20\n",
    "embedding_size = 4  # only used in supporting models.\n",
    "hidden_size = 300\n",
    "rnn_layers = 1\n",
    "dropout = 0.2\n",
    "batch_size = 128\n",
    "\n",
    "# train, test\n",
    "len_list = [4,2]\n",
    "\n",
    "X_coords_list = [[],[]]\n",
    "\n",
    "X_images_list = [[],[]]\n",
    "\n",
    "Y_list = [[],[]]\n",
    "\n",
    "for i, trials in enumerate([train, val]):\n",
    "    random.shuffle(trials)\n",
    "    for trial in trials[:len_list[i]]:\n",
    "        spl = trial.split('_')\n",
    "        if spl[-1] == 'None':\n",
    "            spl[-1] = None\n",
    "        trial_tup = ('_'.join(spl[:-1]), spl[-1])\n",
    "        print(trial_tup)\n",
    "        df_trial, heads = get_trial_data_with_heads_that_are_rotated(trial_tup)\n",
    "\n",
    "        (X_coords, X_images), Y = train_eval.trial_to_samples(df_trial, input_labels, output_labels, inp_seq_len, out_seq_len, 5, input_images=heads)\n",
    "        X_coords_list[i].append(X_coords)\n",
    "        X_images_list[i].append(X_images.float())\n",
    "        Y_list[i].append(Y)       \n",
    "\n",
    "        \n",
    "X_coords_train = torch.cat(X_coords_list[0])\n",
    "X_coords_test = torch.cat(X_coords_list[1])\n",
    "X_images_train = torch.cat(X_images_list[0])\n",
    "X_images_test = torch.cat(X_images_list[1])\n",
    "Y_train = torch.cat(Y_list[0])\n",
    "Y_test = torch.cat(Y_list[1])\n",
    "\n",
    "dataset_train_wh = train_eval.TrajectoriesDataWithHeads(X_coords_train, X_images_train, Y_train)\n",
    "dataset_test_wh = train_eval.TrajectoriesDataWithHeads(X_coords_test, X_images_test, Y_test)\n",
    "dataset_train = train_eval.TrajectoriesData(X_coords_train, Y_train)\n",
    "dataset_test = train_eval.TrajectoriesData(X_coords_test, Y_test)\n",
    "\n",
    "\n",
    "dl_train_wh = torch.utils.data.DataLoader(dataset_train_wh, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "dl_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "dl_test_wh = torch.utils.data.DataLoader(dataset_test_wh, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "dl_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
