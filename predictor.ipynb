{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Prediction import predictor\n",
    "from Prediction import visualize\n",
    "from Prediction import detector\n",
    "from Prediction import kalman_predict\n",
    "from Prediction import LSTM_predict\n",
    "import imp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detector initiated successfully\n"
     ]
    }
   ],
   "source": [
    "det = detector.Detector_v4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_predictor = kalman_predict.ConstantVelocityKalmanPredictor(forecast_horizon=60)\n",
    "p = predictor.HitPredictor(traj_predictor, det, history_size=5288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5080/5080 [02:24<00:00, 35.25it/s]\n"
     ]
    }
   ],
   "source": [
    "imp.reload(visualize)\n",
    "\n",
    "vid_path = \"../Pogona_Pursuit/Arena/experiments/fast_cockroach_line_20200730T131606/trial1/videos/20200730-131607/19506468.avi\"\n",
    "out_path = \"labelled/test_kalman_predictor.mp4\"\n",
    "\n",
    "p.reset(history_size=5288)\n",
    "visualize.process_video(vid_path, out_path, [visualize.predictor_visualizer(p)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RED (lstm+dense) Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Prediction.visualize' from '/app/Pogona_realtime/Prediction/visualize.py'>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(LSTM_predict)\n",
    "imp.reload(predictor)\n",
    "imp.reload(visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'Prediction/traj_models/RED/model_16_24_h32_best.pth'\n",
    "red_predictor = LSTM_predict.REDPredictor(model_path, 16, 24, hidden_size=32)\n",
    "red_hitp = predictor.HitPredictor(red_predictor, det, history_size=5288, prediction_y_threshold=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 4645/5080 [02:13<00:12, 34.92it/s]"
     ]
    }
   ],
   "source": [
    "vid_path = \"../Pogona_Pursuit/Arena/experiments/fast_cockroach_line_20200730T131606/trial1/videos/20200730-131607/19506468.avi\"\n",
    "out_path = \"labelled/test_red1624_265e_h32_predictor.mp4\"\n",
    "\n",
    "red_hitp.reset(history_size=5288)\n",
    "visualize.process_video(vid_path, out_path, [visualize.predictor_visualizer(red_hitp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[861.61036691, 804.79697061],\n",
       "       [861.76925268, 804.72620213],\n",
       "       [862.02007188, 804.675472  ],\n",
       "       [862.36913661, 804.67548648],\n",
       "       [862.73166099, 804.67376638],\n",
       "       [863.18446268, 804.68322696],\n",
       "       [863.58856924, 804.66262528],\n",
       "       [864.00353477, 804.69567456],\n",
       "       [864.47081025, 804.73510178],\n",
       "       [864.92157336, 804.7507731 ],\n",
       "       [865.35339297, 804.80218187],\n",
       "       [865.83946969, 804.82385796],\n",
       "       [866.30263467, 804.83434297],\n",
       "       [866.69464557, 804.84661949],\n",
       "       [867.06874341, 804.87738   ],\n",
       "       [867.40941592, 804.91605266],\n",
       "       [867.74185781, 804.98194481],\n",
       "       [868.0523302 , 805.05609493],\n",
       "       [868.28882477, 805.15725798],\n",
       "       [868.50150843, 805.21606584],\n",
       "       [868.6737972 , 805.263766  ],\n",
       "       [868.84576888, 805.26452107],\n",
       "       [868.96103797, 805.21953151],\n",
       "       [869.12961698, 805.22035179]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_hitp.forecasts[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f81606e8c50>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cents = detector.xywh_to_centroid(red_hitp.history[60:90])\n",
    "plt.scatter(cents[:, 0], cents[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv.imread('./Calib_frames/blk_sqr.jpg',)\n",
    "im = cv.cvtColor(im,cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "im416 = cv.resize(im,(416,416))\n",
    "im800_600 = cv.resize(im,(800,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1440)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.rand(1440,1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214 µs ± 3.47 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cv.resize(r,(416,416))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.6 ms ± 36.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit p.handle_frame(im416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9 ms ± 43.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit p.handle_frame(im800_600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.6 ms ± 128 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit p.handle_frame(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check net object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from Prediction.detector import Detector_v4\n",
    "from pprint import pprint\n",
    "from ctypes import CDLL, RTLD_GLOBAL, c_void_p, c_int\n",
    "import ctypes\n",
    "from Prediction.Yolo4.darknet import IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detector initiated successfully\n"
     ]
    }
   ],
   "source": [
    "lib = CDLL(\"./Prediction/Yolo4/libdarknet.so\", RTLD_GLOBAL)\n",
    "det = Detector_v4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ctypes.c_void_p"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_p = ctypes.cast(det.net, ctypes.c_void_p)\n",
    "inspect.getmembers(net_p)\n",
    "type(net_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_network_layer = lib.get_network_layer\n",
    "get_network_layer.argtypes = [c_void_p, c_int]\n",
    "get_network_layer.restype = c_void_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94731766474080"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = get_network_layer(det.net, 0)\n",
    "\n",
    "\"\"\"\n",
    "struct layer {\n",
    "    LAYER_TYPE type;\n",
    "    ACTIVATION activation;\n",
    "    ACTIVATION lstm_activation;\n",
    "    COST_TYPE cost_type;\n",
    "    void(*forward)   (struct layer, struct network_state);\n",
    "    void(*backward)  (struct layer, struct network_state);\n",
    "    void(*update)    (struct layer, int, float, float, float);\n",
    "    void(*forward_gpu)   (struct layer, struct network_state);\n",
    "    void(*backward_gpu)  (struct layer, struct network_state);\n",
    "    void(*update_gpu)    (struct layer, int, float, float, float, float);\n",
    "    layer *share_layer;\n",
    "    int train;\n",
    "    int avgpool;\n",
    "    int batch_normalize;\n",
    "    int shortcut;\n",
    "    int batch;\n",
    "    int dynamic_minibatch;\n",
    "    int forced;\n",
    "    int flipped;\n",
    "    int inputs;\n",
    "    int outputs;\n",
    "    float mean_alpha;\n",
    "    int nweights;\n",
    "    int nbiases;\n",
    "    int extra;\n",
    "    int truths;\n",
    "    int h, w, c;\n",
    "    int out_h, out_w, out_c;\n",
    "    int n;\n",
    "    int max_boxes;\n",
    "    int truth_size;\n",
    "    int groups;\n",
    "    int group_id;\n",
    "    int size;\n",
    "    int side;\n",
    "    int stride;\n",
    "    int stride_x;\n",
    "    int stride_y;\n",
    "    int dilation;\n",
    "    int antialiasing;\n",
    "    int maxpool_depth;\n",
    "    int maxpool_zero_nonmax;\n",
    "    int out_channels;\n",
    "    float reverse;\n",
    "    int coordconv;\n",
    "    int flatten;\n",
    "    int spatial;\n",
    "    int pad;\n",
    "    int sqrt;\n",
    "    int flip;\n",
    "    int index;\n",
    "    int scale_wh;\n",
    "    int binary;\n",
    "    int xnor;\n",
    "    int peephole;\n",
    "    int use_bin_output;\n",
    "    int keep_delta_gpu;\n",
    "    int optimized_memory;\n",
    "    int steps;\n",
    "    int history_size;\n",
    "    int bottleneck;\n",
    "    float time_normalizer;\n",
    "    int state_constrain;\n",
    "    int hidden;\n",
    "    int truth;\n",
    "    float smooth;\n",
    "    float dot;\n",
    "    int deform;\n",
    "    int grad_centr;\n",
    "    int sway;\n",
    "    int rotate;\n",
    "    int stretch;\n",
    "    int stretch_sway;\n",
    "    float angle;\n",
    "    float jitter;\n",
    "    float resize;\n",
    "    float saturation;\n",
    "    float exposure;\n",
    "    float shift;\n",
    "    float ratio;\n",
    "    float learning_rate_scale;\n",
    "    float clip;\n",
    "    int focal_loss;\n",
    "    float *classes_multipliers;\n",
    "    float label_smooth_eps;\n",
    "    int noloss;\n",
    "    int softmax;\n",
    "    int classes;\n",
    "    int detection;\n",
    "    int embedding_layer_id;\n",
    "    float *embedding_output;\n",
    "    int embedding_size;\n",
    "    float sim_thresh;\n",
    "    int track_history_size;\n",
    "    int dets_for_track;\n",
    "    int dets_for_show;\n",
    "    float track_ciou_norm;\n",
    "    int coords;\n",
    "    int background;\n",
    "    int rescore;\n",
    "    int objectness;\n",
    "    int does_cost;\n",
    "    int joint;\n",
    "    int noadjust;\n",
    "    int reorg;\n",
    "    int log;\n",
    "    int tanh;\n",
    "    int *mask;\n",
    "    int total;\n",
    "    float bflops;\n",
    "\n",
    "    int adam;\n",
    "    float B1;\n",
    "    float B2;\n",
    "    float eps;\n",
    "\n",
    "    int t;\n",
    "\n",
    "    float alpha;\n",
    "    float beta;\n",
    "    float kappa;\n",
    "\n",
    "    float coord_scale;\n",
    "    float object_scale;\n",
    "    float noobject_scale;\n",
    "    float mask_scale;\n",
    "    float class_scale;\n",
    "    int bias_match;\n",
    "    float random;\n",
    "    float ignore_thresh;\n",
    "    float truth_thresh;\n",
    "    float iou_thresh;\n",
    "    float thresh;\n",
    "    float focus;\n",
    "    int classfix;\n",
    "    int absolute;\n",
    "    int assisted_excitation;\n",
    "\n",
    "    int onlyforward;\n",
    "    int stopbackward;\n",
    "    int train_only_bn;\n",
    "    int dont_update;\n",
    "    int burnin_update;\n",
    "    int dontload;\n",
    "    int dontsave;\n",
    "    int dontloadscales;\n",
    "    int numload;\n",
    "\n",
    "    float temperature;\n",
    "    float probability;\n",
    "    float dropblock_size_rel;\n",
    "    int dropblock_size_abs;\n",
    "    int dropblock;\n",
    "    float scale;\n",
    "\n",
    "    int receptive_w;\n",
    "    int receptive_h;\n",
    "    int receptive_w_scale;\n",
    "    int receptive_h_scale;\n",
    "\n",
    "    char  * cweights;\n",
    "    int   * indexes;\n",
    "    int   * input_layers;\n",
    "    int   * input_sizes;\n",
    "    float **layers_output;\n",
    "    float **layers_delta;\n",
    "    WEIGHTS_TYPE_T weights_type;\n",
    "    WEIGHTS_NORMALIZATION_T weights_normalization;\n",
    "    int   * map;\n",
    "    int   * counts;\n",
    "    float ** sums;\n",
    "    float * rand;\n",
    "    float * cost;\n",
    "    int *labels;\n",
    "    float *cos_sim;\n",
    "    float *exp_cos_sim;\n",
    "    float *p_constrastive;\n",
    "    contrastive_params *contrast_p_gpu;\n",
    "    float * state;\n",
    "    float * prev_state;\n",
    "    float * forgot_state;\n",
    "    float * forgot_delta;\n",
    "    float * state_delta;\n",
    "    float * combine_cpu;\n",
    "    float * combine_delta_cpu;\n",
    "\n",
    "    float *concat;\n",
    "    float *concat_delta;\n",
    "\n",
    "    float *binary_weights;\n",
    "\n",
    "    float *biases;\n",
    "    float *bias_updates;\n",
    "\n",
    "    float *scales;\n",
    "    float *scale_updates;\n",
    "\n",
    "    float *weights;\n",
    "    float *weight_updates;\n",
    "\n",
    "    float scale_x_y;\n",
    "    int objectness_smooth;\n",
    "    float max_delta;\n",
    "    float uc_normalizer;\n",
    "    float iou_normalizer;\n",
    "    float cls_normalizer;\n",
    "    IOU_LOSS iou_loss;\n",
    "    IOU_LOSS iou_thresh_kind;\n",
    "    NMS_KIND nms_kind;\n",
    "    float beta_nms;\n",
    "    YOLO_POINT yolo_point;\n",
    "\n",
    "    char *align_bit_weights_gpu;\n",
    "    float *mean_arr_gpu;\n",
    "    float *align_workspace_gpu;\n",
    "    float *transposed_align_workspace_gpu;\n",
    "    int align_workspace_size;\n",
    "\n",
    "    char *align_bit_weights;\n",
    "    float *mean_arr;\n",
    "    int align_bit_weights_size;\n",
    "    int lda_align;\n",
    "    int new_lda;\n",
    "    int bit_align;\n",
    "\n",
    "    float *col_image;\n",
    "    float * delta;\n",
    "    float * output;\n",
    "    float * activation_input;\n",
    "    int delta_pinned;\n",
    "    int output_pinned;\n",
    "    float * loss;\n",
    "    float * squared;\n",
    "    float * norms;\n",
    "\n",
    "    float * spatial_mean;\n",
    "    float * mean;\n",
    "    float * variance;\n",
    "\n",
    "    float * mean_delta;\n",
    "    float * variance_delta;\n",
    "\n",
    "    float * rolling_mean;\n",
    "    float * rolling_variance;\n",
    "\n",
    "    float * x;\n",
    "    float * x_norm;\n",
    "\n",
    "    float * m;\n",
    "    float * v;\n",
    "\n",
    "    float * bias_m;\n",
    "    float * bias_v;\n",
    "    float * scale_m;\n",
    "    float * scale_v;\n",
    "\n",
    "\n",
    "    float *z_cpu;\n",
    "    float *r_cpu;\n",
    "    float *h_cpu;\n",
    "    float *stored_h_cpu;\n",
    "    float * prev_state_cpu;\n",
    "\n",
    "    float *temp_cpu;\n",
    "    float *temp2_cpu;\n",
    "    float *temp3_cpu;\n",
    "\n",
    "    float *dh_cpu;\n",
    "    float *hh_cpu;\n",
    "    float *prev_cell_cpu;\n",
    "    float *cell_cpu;\n",
    "    float *f_cpu;\n",
    "    float *i_cpu;\n",
    "    float *g_cpu;\n",
    "    float *o_cpu;\n",
    "    float *c_cpu;\n",
    "    float *stored_c_cpu;\n",
    "    float *dc_cpu;\n",
    "\n",
    "    float *binary_input;\n",
    "    uint32_t *bin_re_packed_input;\n",
    "    char *t_bit_input;\n",
    "\n",
    "    struct layer *input_layer;\n",
    "    struct layer *self_layer;\n",
    "    struct layer *output_layer;\n",
    "\n",
    "    struct layer *reset_layer;\n",
    "    struct layer *update_layer;\n",
    "    struct layer *state_layer;\n",
    "\n",
    "    struct layer *input_gate_layer;\n",
    "    struct layer *state_gate_layer;\n",
    "    struct layer *input_save_layer;\n",
    "    struct layer *state_save_layer;\n",
    "    struct layer *input_state_layer;\n",
    "    struct layer *state_state_layer;\n",
    "\n",
    "    struct layer *input_z_layer;\n",
    "    struct layer *state_z_layer;\n",
    "\n",
    "    struct layer *input_r_layer;\n",
    "    struct layer *state_r_layer;\n",
    "\n",
    "    struct layer *input_h_layer;\n",
    "    struct layer *state_h_layer;\n",
    "\n",
    "    struct layer *wz;\n",
    "    struct layer *uz;\n",
    "    struct layer *wr;\n",
    "    struct layer *ur;\n",
    "    struct layer *wh;\n",
    "    struct layer *uh;\n",
    "    struct layer *uo;\n",
    "    struct layer *wo;\n",
    "    struct layer *vo;\n",
    "    struct layer *uf;\n",
    "    struct layer *wf;\n",
    "    struct layer *vf;\n",
    "    struct layer *ui;\n",
    "    struct layer *wi;\n",
    "    struct layer *vi;\n",
    "    struct layer *ug;\n",
    "    struct layer *wg;\n",
    "\n",
    "    tree *softmax_tree;\n",
    "\n",
    "    size_t workspace_size;\n",
    "\n",
    "//#ifdef GPU\n",
    "    int *indexes_gpu;\n",
    "\n",
    "    float *z_gpu;\n",
    "    float *r_gpu;\n",
    "    float *h_gpu;\n",
    "    float *stored_h_gpu;\n",
    "    float *bottelneck_hi_gpu;\n",
    "    float *bottelneck_delta_gpu;\n",
    "\n",
    "    float *temp_gpu;\n",
    "    float *temp2_gpu;\n",
    "    float *temp3_gpu;\n",
    "\n",
    "    float *dh_gpu;\n",
    "    float *hh_gpu;\n",
    "    float *prev_cell_gpu;\n",
    "    float *prev_state_gpu;\n",
    "    float *last_prev_state_gpu;\n",
    "    float *last_prev_cell_gpu;\n",
    "    float *cell_gpu;\n",
    "    float *f_gpu;\n",
    "    float *i_gpu;\n",
    "    float *g_gpu;\n",
    "    float *o_gpu;\n",
    "    float *c_gpu;\n",
    "    float *stored_c_gpu;\n",
    "    float *dc_gpu;\n",
    "\n",
    "    // adam\n",
    "    float *m_gpu;\n",
    "    float *v_gpu;\n",
    "    float *bias_m_gpu;\n",
    "    float *scale_m_gpu;\n",
    "    float *bias_v_gpu;\n",
    "    float *scale_v_gpu;\n",
    "\n",
    "    float * combine_gpu;\n",
    "    float * combine_delta_gpu;\n",
    "\n",
    "    float * forgot_state_gpu;\n",
    "    float * forgot_delta_gpu;\n",
    "    float * state_gpu;\n",
    "    float * state_delta_gpu;\n",
    "    float * gate_gpu;\n",
    "    float * gate_delta_gpu;\n",
    "    float * save_gpu;\n",
    "    float * save_delta_gpu;\n",
    "    float * concat_gpu;\n",
    "    float * concat_delta_gpu;\n",
    "\n",
    "    float *binary_input_gpu;\n",
    "    float *binary_weights_gpu;\n",
    "    float *bin_conv_shortcut_in_gpu;\n",
    "    float *bin_conv_shortcut_out_gpu;\n",
    "\n",
    "    float * mean_gpu;\n",
    "    float * variance_gpu;\n",
    "    float * m_cbn_avg_gpu;\n",
    "    float * v_cbn_avg_gpu;\n",
    "\n",
    "    float * rolling_mean_gpu;\n",
    "    float * rolling_variance_gpu;\n",
    "\n",
    "    float * variance_delta_gpu;\n",
    "    float * mean_delta_gpu;\n",
    "\n",
    "    float * col_image_gpu;\n",
    "\n",
    "    float * x_gpu;\n",
    "    float * x_norm_gpu;\n",
    "    float * weights_gpu;\n",
    "    float * weight_updates_gpu;\n",
    "    float * weight_deform_gpu;\n",
    "    float * weight_change_gpu;\n",
    "\n",
    "    float * weights_gpu16;\n",
    "    float * weight_updates_gpu16;\n",
    "\n",
    "    float * biases_gpu;\n",
    "    float * bias_updates_gpu;\n",
    "    float * bias_change_gpu;\n",
    "\n",
    "    float * scales_gpu;\n",
    "    float * scale_updates_gpu;\n",
    "    float * scale_change_gpu;\n",
    "\n",
    "    float * input_antialiasing_gpu;\n",
    "    float * output_gpu;\n",
    "    float * output_avg_gpu;\n",
    "    float * activation_input_gpu;\n",
    "    float * loss_gpu;\n",
    "    float * delta_gpu;\n",
    "    float * cos_sim_gpu;\n",
    "    float * rand_gpu;\n",
    "    float * drop_blocks_scale;\n",
    "    float * drop_blocks_scale_gpu;\n",
    "    float * squared_gpu;\n",
    "    float * norms_gpu;\n",
    "\n",
    "    float *gt_gpu;\n",
    "    float *a_avg_gpu;\n",
    "\n",
    "    int *input_sizes_gpu;\n",
    "    float **layers_output_gpu;\n",
    "    float **layers_delta_gpu;\n",
    "#ifdef CUDNN\n",
    "    cudnnTensorDescriptor_t srcTensorDesc, dstTensorDesc;\n",
    "    cudnnTensorDescriptor_t srcTensorDesc16, dstTensorDesc16;\n",
    "    cudnnTensorDescriptor_t dsrcTensorDesc, ddstTensorDesc;\n",
    "    cudnnTensorDescriptor_t dsrcTensorDesc16, ddstTensorDesc16;\n",
    "    cudnnTensorDescriptor_t normTensorDesc, normDstTensorDesc, normDstTensorDescF16;\n",
    "    cudnnFilterDescriptor_t weightDesc, weightDesc16;\n",
    "    cudnnFilterDescriptor_t dweightDesc, dweightDesc16;\n",
    "    cudnnConvolutionDescriptor_t convDesc;\n",
    "    cudnnConvolutionFwdAlgo_t fw_algo, fw_algo16;\n",
    "    cudnnConvolutionBwdDataAlgo_t bd_algo, bd_algo16;\n",
    "    cudnnConvolutionBwdFilterAlgo_t bf_algo, bf_algo16;\n",
    "    cudnnPoolingDescriptor_t poolingDesc;\n",
    "#else   // CUDNN\n",
    "    void* srcTensorDesc, *dstTensorDesc;\n",
    "    void* srcTensorDesc16, *dstTensorDesc16;\n",
    "    void* dsrcTensorDesc, *ddstTensorDesc;\n",
    "    void* dsrcTensorDesc16, *ddstTensorDesc16;\n",
    "    void* normTensorDesc, *normDstTensorDesc, *normDstTensorDescF16;\n",
    "    void* weightDesc, *weightDesc16;\n",
    "    void* dweightDesc, *dweightDesc16;\n",
    "    void* convDesc;\n",
    "    UNUSED_ENUM_TYPE fw_algo, fw_algo16;\n",
    "    UNUSED_ENUM_TYPE bd_algo, bd_algo16;\n",
    "    UNUSED_ENUM_TYPE bf_algo, bf_algo16;\n",
    "    void* poolingDesc;\n",
    "#endif  // CUDNN\n",
    "//#endif  // GPU\n",
    "};\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DarknetLayer(ctypes.Structure):\n",
    "    _fields_ = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Prediction import dataset\n",
    "from Prediction import LSTM_predict as lstm\n",
    "from Prediction import train_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Prediction.train_eval' from '/app/Pogona_realtime/Prediction/train_eval.py'>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(dataset)\n",
    "imp.reload(train_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Prediction.LSTM_predict' from '/app/Pogona_realtime/Prediction/LSTM_predict.py'>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/all_exper.p','rb') as f:\n",
    "    d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = dataset.get_unified_df(d,mult=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.assign(vx=test['centroid_x'].diff().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>centroid_x</th>\n",
       "      <th>centroid_y</th>\n",
       "      <th>left_x</th>\n",
       "      <th>top_y</th>\n",
       "      <th>right_x</th>\n",
       "      <th>bottom_y</th>\n",
       "      <th>conf</th>\n",
       "      <th>num_bbox</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hit_x</th>\n",
       "      <th>hit_y</th>\n",
       "      <th>bug_x</th>\n",
       "      <th>bug_y</th>\n",
       "      <th>touch_ts</th>\n",
       "      <th>hit</th>\n",
       "      <th>frame_ind</th>\n",
       "      <th>vx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">line_20200803T081429</th>\n",
       "      <th>1</th>\n",
       "      <td>1001.973328</td>\n",
       "      <td>744.859730</td>\n",
       "      <td>951.973328</td>\n",
       "      <td>704.859730</td>\n",
       "      <td>1053.493713</td>\n",
       "      <td>785.472546</td>\n",
       "      <td>0.988369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-08-03 08:14:29.869937658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001.659409</td>\n",
       "      <td>743.726990</td>\n",
       "      <td>951.659409</td>\n",
       "      <td>703.726990</td>\n",
       "      <td>1052.953751</td>\n",
       "      <td>785.046570</td>\n",
       "      <td>0.993245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-08-03 08:14:29.918991566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.313919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001.980980</td>\n",
       "      <td>744.570805</td>\n",
       "      <td>951.980980</td>\n",
       "      <td>704.570805</td>\n",
       "      <td>1052.929787</td>\n",
       "      <td>785.393673</td>\n",
       "      <td>0.992465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-08-03 08:14:29.934581041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.321571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001.342079</td>\n",
       "      <td>743.889633</td>\n",
       "      <td>951.342079</td>\n",
       "      <td>703.889633</td>\n",
       "      <td>1052.917442</td>\n",
       "      <td>785.432266</td>\n",
       "      <td>0.992419</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-08-03 08:14:29.947722673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.638901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001.882412</td>\n",
       "      <td>744.529049</td>\n",
       "      <td>951.882412</td>\n",
       "      <td>704.529049</td>\n",
       "      <td>1053.409702</td>\n",
       "      <td>785.115849</td>\n",
       "      <td>0.993147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-08-03 08:14:29.959564209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.540333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         centroid_x  centroid_y      left_x       top_y  \\\n",
       "line_20200803T081429 1  1001.973328  744.859730  951.973328  704.859730   \n",
       "                     1  1001.659409  743.726990  951.659409  703.726990   \n",
       "                     1  1001.980980  744.570805  951.980980  704.570805   \n",
       "                     1  1001.342079  743.889633  951.342079  703.889633   \n",
       "                     1  1001.882412  744.529049  951.882412  704.529049   \n",
       "\n",
       "                            right_x    bottom_y      conf  num_bbox  \\\n",
       "line_20200803T081429 1  1053.493713  785.472546  0.988369       1.0   \n",
       "                     1  1052.953751  785.046570  0.993245       1.0   \n",
       "                     1  1052.929787  785.393673  0.992465       1.0   \n",
       "                     1  1052.917442  785.432266  0.992419       1.0   \n",
       "                     1  1053.409702  785.115849  0.993147       1.0   \n",
       "\n",
       "                                           timestamp  hit_x  hit_y  bug_x  \\\n",
       "line_20200803T081429 1 2020-08-03 08:14:29.869937658    NaN    NaN    NaN   \n",
       "                     1 2020-08-03 08:14:29.918991566    NaN    NaN    NaN   \n",
       "                     1 2020-08-03 08:14:29.934581041    NaN    NaN    NaN   \n",
       "                     1 2020-08-03 08:14:29.947722673    NaN    NaN    NaN   \n",
       "                     1 2020-08-03 08:14:29.959564209    NaN    NaN    NaN   \n",
       "\n",
       "                        bug_y touch_ts    hit  frame_ind        vx  \n",
       "line_20200803T081429 1    NaN      NaT  False          0       NaN  \n",
       "                     1    NaN      NaT  False          1 -0.313919  \n",
       "                     1    NaN      NaT  False          2  0.321571  \n",
       "                     1    NaN      NaT  False          3 -0.638901  \n",
       "                     1    NaN      NaT  False          4  0.540333  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['vx'] = pd.Series(test['centroid_x'].diff().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_labels = ['centroid_x', 'centroid_y']\n",
    "out_labels = ['centroid_x', 'centroid_y']\n",
    "inp_seq = 16\n",
    "out_seq = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list_X, tensor_list_Y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:2: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for trial in all_df.index.unique():\n",
    "    trial_df = all_df.loc[trial]\n",
    "    trial_df = trial_df.assign(vx=trial_df['centroid_x'].diff().values,\n",
    "                              vy=trial_df['centroid_y'].diff().values)\n",
    "    X, Y = dataset.trial_to_samples(trial_df, input_labels = inp_labels,\n",
    "                                   output_labels=out_labels, input_seq_size=inp_seq,\n",
    "                                   output_seq_size=out_seq)\n",
    "    tensor_list_X.append(X)\n",
    "    tensor_list_Y.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = torch.cat(tensor_list_X)\n",
    "all_Y = torch.cat(tensor_list_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader = train_eval.create_dataloader(all_X, all_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = lstm.LSTMdense(2,2,out_seq, hidden_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1281.671, epoch time: 1.437\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 3.282\n",
      "epoch: 5, loss: 1163.191, epoch time: 1.592\n",
      "++++++++++++++++\n",
      "Eval epoch: 5, Test set mean ADE 3.070\n",
      "epoch: 10, loss: 1134.329, epoch time: 1.497\n",
      "++++++++++++++++\n",
      "Eval epoch: 10, Test set mean ADE 3.004\n",
      "epoch: 15, loss: 1110.864, epoch time: 1.459\n",
      "++++++++++++++++\n",
      "Eval epoch: 15, Test set mean ADE 2.952\n",
      "epoch: 20, loss: 1090.268, epoch time: 1.553\n",
      "++++++++++++++++\n",
      "Eval epoch: 20, Test set mean ADE 2.922\n",
      "epoch: 25, loss: 1072.478, epoch time: 1.481\n",
      "++++++++++++++++\n",
      "Eval epoch: 25, Test set mean ADE 2.887\n",
      "epoch: 30, loss: 1055.722, epoch time: 1.511\n",
      "++++++++++++++++\n",
      "Eval epoch: 30, Test set mean ADE 2.857\n",
      "epoch: 35, loss: 1040.087, epoch time: 1.455\n",
      "++++++++++++++++\n",
      "Eval epoch: 35, Test set mean ADE 2.831\n",
      "epoch: 40, loss: 1026.736, epoch time: 1.454\n",
      "++++++++++++++++\n",
      "Eval epoch: 40, Test set mean ADE 2.803\n",
      "epoch: 45, loss: 1012.521, epoch time: 1.597\n",
      "++++++++++++++++\n",
      "Eval epoch: 45, Test set mean ADE 2.798\n",
      "epoch: 50, loss: 1001.909, epoch time: 1.502\n",
      "++++++++++++++++\n",
      "Eval epoch: 50, Test set mean ADE 2.764\n",
      "epoch: 55, loss: 992.467, epoch time: 1.482\n",
      "++++++++++++++++\n",
      "Eval epoch: 55, Test set mean ADE 2.753\n",
      "epoch: 60, loss: 984.993, epoch time: 1.565\n",
      "++++++++++++++++\n",
      "Eval epoch: 60, Test set mean ADE 2.744\n",
      "epoch: 65, loss: 973.949, epoch time: 1.430\n",
      "++++++++++++++++\n",
      "Eval epoch: 65, Test set mean ADE 2.722\n",
      "epoch: 70, loss: 966.695, epoch time: 1.504\n",
      "++++++++++++++++\n",
      "Eval epoch: 70, Test set mean ADE 2.711\n",
      "epoch: 75, loss: 959.449, epoch time: 1.586\n",
      "++++++++++++++++\n",
      "Eval epoch: 75, Test set mean ADE 2.709\n",
      "epoch: 80, loss: 952.844, epoch time: 1.475\n",
      "++++++++++++++++\n",
      "Eval epoch: 80, Test set mean ADE 2.699\n",
      "epoch: 85, loss: 947.802, epoch time: 1.455\n",
      "++++++++++++++++\n",
      "Eval epoch: 85, Test set mean ADE 2.685\n",
      "epoch: 90, loss: 941.495, epoch time: 1.506\n",
      "++++++++++++++++\n",
      "Eval epoch: 90, Test set mean ADE 2.674\n",
      "epoch: 95, loss: 937.386, epoch time: 1.504\n",
      "++++++++++++++++\n",
      "Eval epoch: 95, Test set mean ADE 2.670\n",
      "epoch: 100, loss: 932.326, epoch time: 1.570\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 2.672\n",
      "epoch: 105, loss: 928.067, epoch time: 1.446\n",
      "++++++++++++++++\n",
      "Eval epoch: 105, Test set mean ADE 2.657\n",
      "epoch: 110, loss: 923.516, epoch time: 1.464\n",
      "++++++++++++++++\n",
      "Eval epoch: 110, Test set mean ADE 2.663\n",
      "epoch: 115, loss: 920.232, epoch time: 1.594\n",
      "++++++++++++++++\n",
      "Eval epoch: 115, Test set mean ADE 2.651\n",
      "epoch: 120, loss: 917.420, epoch time: 1.503\n",
      "++++++++++++++++\n",
      "Eval epoch: 120, Test set mean ADE 2.662\n",
      "epoch: 125, loss: 914.470, epoch time: 1.451\n",
      "++++++++++++++++\n",
      "Eval epoch: 125, Test set mean ADE 2.650\n",
      "epoch: 130, loss: 912.710, epoch time: 1.579\n",
      "++++++++++++++++\n",
      "Eval epoch: 130, Test set mean ADE 2.648\n",
      "epoch: 135, loss: 908.703, epoch time: 1.509\n",
      "++++++++++++++++\n",
      "Eval epoch: 135, Test set mean ADE 2.639\n",
      "epoch: 140, loss: 905.301, epoch time: 1.498\n",
      "++++++++++++++++\n",
      "Eval epoch: 140, Test set mean ADE 2.650\n",
      "epoch: 145, loss: 902.780, epoch time: 1.491\n",
      "++++++++++++++++\n",
      "Eval epoch: 145, Test set mean ADE 2.641\n",
      "epoch: 150, loss: 902.075, epoch time: 1.461\n",
      "++++++++++++++++\n",
      "Eval epoch: 150, Test set mean ADE 2.636\n",
      "epoch: 155, loss: 899.054, epoch time: 1.592\n",
      "++++++++++++++++\n",
      "Eval epoch: 155, Test set mean ADE 2.633\n",
      "epoch: 160, loss: 896.960, epoch time: 1.502\n",
      "++++++++++++++++\n",
      "Eval epoch: 160, Test set mean ADE 2.635\n",
      "epoch: 165, loss: 894.430, epoch time: 1.492\n",
      "++++++++++++++++\n",
      "Eval epoch: 165, Test set mean ADE 2.639\n",
      "epoch: 170, loss: 891.561, epoch time: 1.564\n",
      "++++++++++++++++\n",
      "Eval epoch: 170, Test set mean ADE 2.626\n",
      "epoch: 175, loss: 890.817, epoch time: 1.513\n",
      "++++++++++++++++\n",
      "Eval epoch: 175, Test set mean ADE 2.630\n",
      "epoch: 180, loss: 888.645, epoch time: 1.453\n",
      "++++++++++++++++\n",
      "Eval epoch: 180, Test set mean ADE 2.626\n",
      "epoch: 185, loss: 886.009, epoch time: 1.567\n",
      "++++++++++++++++\n",
      "Eval epoch: 185, Test set mean ADE 2.622\n",
      "epoch: 190, loss: 884.408, epoch time: 1.432\n",
      "++++++++++++++++\n",
      "Eval epoch: 190, Test set mean ADE 2.619\n",
      "epoch: 195, loss: 882.000, epoch time: 1.478\n",
      "++++++++++++++++\n",
      "Eval epoch: 195, Test set mean ADE 2.630\n",
      "epoch: 200, loss: 880.618, epoch time: 1.573\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 2.622\n",
      "epoch: 205, loss: 879.701, epoch time: 1.477\n",
      "++++++++++++++++\n",
      "Eval epoch: 205, Test set mean ADE 2.607\n",
      "epoch: 210, loss: 878.900, epoch time: 1.532\n",
      "++++++++++++++++\n",
      "Eval epoch: 210, Test set mean ADE 2.615\n",
      "epoch: 215, loss: 876.405, epoch time: 1.499\n",
      "++++++++++++++++\n",
      "Eval epoch: 215, Test set mean ADE 2.616\n",
      "epoch: 220, loss: 874.466, epoch time: 1.489\n",
      "++++++++++++++++\n",
      "Eval epoch: 220, Test set mean ADE 2.610\n",
      "epoch: 225, loss: 873.209, epoch time: 1.571\n",
      "++++++++++++++++\n",
      "Eval epoch: 225, Test set mean ADE 2.604\n",
      "epoch: 230, loss: 871.808, epoch time: 1.471\n",
      "++++++++++++++++\n",
      "Eval epoch: 230, Test set mean ADE 2.615\n",
      "epoch: 235, loss: 869.007, epoch time: 1.519\n",
      "++++++++++++++++\n",
      "Eval epoch: 235, Test set mean ADE 2.609\n",
      "epoch: 240, loss: 868.669, epoch time: 1.586\n",
      "++++++++++++++++\n",
      "Eval epoch: 240, Test set mean ADE 2.603\n",
      "epoch: 245, loss: 868.354, epoch time: 1.487\n",
      "++++++++++++++++\n",
      "Eval epoch: 245, Test set mean ADE 2.605\n",
      "epoch: 250, loss: 864.982, epoch time: 1.461\n",
      "++++++++++++++++\n",
      "Eval epoch: 250, Test set mean ADE 2.599\n",
      "epoch: 255, loss: 865.745, epoch time: 1.583\n",
      "++++++++++++++++\n",
      "Eval epoch: 255, Test set mean ADE 2.601\n",
      "epoch: 260, loss: 864.179, epoch time: 1.503\n",
      "++++++++++++++++\n",
      "Eval epoch: 260, Test set mean ADE 2.605\n",
      "epoch: 265, loss: 863.019, epoch time: 1.572\n",
      "++++++++++++++++\n",
      "Eval epoch: 265, Test set mean ADE 2.599\n",
      "epoch: 270, loss: 861.177, epoch time: 1.464\n",
      "++++++++++++++++\n",
      "Eval epoch: 270, Test set mean ADE 2.602\n",
      "epoch: 275, loss: 863.021, epoch time: 1.508\n",
      "++++++++++++++++\n",
      "Eval epoch: 275, Test set mean ADE 2.605\n",
      "epoch: 280, loss: 861.191, epoch time: 1.596\n",
      "++++++++++++++++\n",
      "Eval epoch: 280, Test set mean ADE 2.602\n",
      "epoch: 285, loss: 858.594, epoch time: 1.484\n",
      "++++++++++++++++\n",
      "Eval epoch: 285, Test set mean ADE 2.606\n",
      "epoch: 290, loss: 857.324, epoch time: 1.436\n",
      "++++++++++++++++\n",
      "Eval epoch: 290, Test set mean ADE 2.601\n",
      "epoch: 295, loss: 857.311, epoch time: 1.592\n",
      "++++++++++++++++\n",
      "Eval epoch: 295, Test set mean ADE 2.607\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "best_epoch, best_ADE = train_eval.train_trajectory_model(net, train_dataloader, test_dataloader, 300, \n",
    "              'Prediction/traj_models/RED/', eval_freq=5, epoch_print_freq=5, model_name=\"model_16_24_h32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 27661.298828125)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch, best_ADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Prediction.train_eval' from '/app/Pogona_realtime/Prediction/train_eval.py'>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(train_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with input_seq_len=12, output_seq_len=12\n",
      "epoch: 0, loss: 777.553, epoch time: 1.367\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 2.219\n",
      "epoch: 50, loss: 337.948, epoch time: 1.450\n",
      "epoch: 100, loss: 268.827, epoch time: 1.472\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 2.496\n",
      "epoch: 150, loss: 241.172, epoch time: 1.438\n",
      "epoch: 200, loss: 227.790, epoch time: 1.429\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 2.527\n",
      "epoch: 250, loss: 219.896, epoch time: 1.480\n",
      "epoch: 300, loss: 214.207, epoch time: 1.455\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 2.549\n",
      "epoch: 350, loss: 210.148, epoch time: 1.434\n",
      "epoch: 400, loss: 206.672, epoch time: 1.524\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 2.563\n",
      "Finished training\n",
      "Training with input_seq_len=12, output_seq_len=20\n",
      "epoch: 0, loss: 1068.994, epoch time: 1.496\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 2.946\n",
      "epoch: 50, loss: 444.467, epoch time: 1.441\n",
      "epoch: 100, loss: 335.257, epoch time: 1.513\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 3.373\n",
      "epoch: 150, loss: 292.342, epoch time: 1.452\n",
      "epoch: 200, loss: 272.156, epoch time: 1.531\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 3.398\n",
      "epoch: 250, loss: 260.763, epoch time: 1.438\n",
      "epoch: 300, loss: 254.370, epoch time: 1.538\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 3.412\n",
      "epoch: 350, loss: 248.962, epoch time: 1.453\n",
      "epoch: 400, loss: 244.695, epoch time: 1.538\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 3.440\n",
      "Finished training\n",
      "Training with input_seq_len=12, output_seq_len=28\n",
      "epoch: 0, loss: 1345.044, epoch time: 1.433\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 3.667\n",
      "epoch: 50, loss: 537.651, epoch time: 1.470\n",
      "epoch: 100, loss: 394.993, epoch time: 1.467\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 4.217\n",
      "epoch: 150, loss: 334.435, epoch time: 1.539\n",
      "epoch: 200, loss: 308.234, epoch time: 1.473\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 4.287\n",
      "epoch: 250, loss: 293.690, epoch time: 1.516\n",
      "epoch: 300, loss: 284.682, epoch time: 1.453\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 4.296\n",
      "epoch: 350, loss: 278.079, epoch time: 1.469\n",
      "epoch: 400, loss: 273.291, epoch time: 1.453\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 4.292\n",
      "Finished training\n",
      "Training with input_seq_len=12, output_seq_len=36\n",
      "epoch: 0, loss: 1600.982, epoch time: 1.496\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 4.370\n",
      "epoch: 50, loss: 642.838, epoch time: 1.460\n",
      "epoch: 100, loss: 450.072, epoch time: 1.470\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 5.057\n",
      "epoch: 150, loss: 374.495, epoch time: 1.476\n",
      "epoch: 200, loss: 343.011, epoch time: 1.545\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 5.083\n",
      "epoch: 250, loss: 325.623, epoch time: 1.649\n",
      "epoch: 300, loss: 313.594, epoch time: 1.540\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 5.090\n",
      "epoch: 350, loss: 305.988, epoch time: 1.526\n",
      "epoch: 400, loss: 300.268, epoch time: 1.551\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 5.105\n",
      "Finished training\n",
      "Training with input_seq_len=12, output_seq_len=44\n",
      "epoch: 0, loss: 1841.573, epoch time: 1.637\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 4.932\n",
      "epoch: 50, loss: 753.801, epoch time: 1.532\n",
      "epoch: 100, loss: 527.360, epoch time: 1.522\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 5.787\n",
      "epoch: 150, loss: 427.888, epoch time: 1.627\n",
      "epoch: 200, loss: 385.234, epoch time: 1.464\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 5.784\n",
      "epoch: 250, loss: 362.047, epoch time: 1.457\n",
      "epoch: 300, loss: 346.620, epoch time: 1.532\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 5.821\n",
      "epoch: 350, loss: 336.111, epoch time: 1.475\n",
      "epoch: 400, loss: 328.431, epoch time: 1.480\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 5.835\n",
      "Finished training\n",
      "Training with input_seq_len=20, output_seq_len=12\n",
      "epoch: 0, loss: 766.133, epoch time: 2.261\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 2.193\n",
      "epoch: 50, loss: 296.876, epoch time: 2.162\n",
      "epoch: 100, loss: 236.432, epoch time: 2.125\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 2.510\n",
      "epoch: 150, loss: 220.527, epoch time: 2.224\n",
      "epoch: 200, loss: 209.812, epoch time: 2.220\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 2.535\n",
      "epoch: 250, loss: 202.461, epoch time: 2.184\n",
      "epoch: 300, loss: 196.995, epoch time: 2.189\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 2.559\n",
      "epoch: 350, loss: 191.298, epoch time: 2.361\n",
      "epoch: 400, loss: 187.073, epoch time: 2.376\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 2.571\n",
      "Finished training\n",
      "Training with input_seq_len=20, output_seq_len=20\n",
      "epoch: 0, loss: 1052.723, epoch time: 2.190\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 2.937\n",
      "epoch: 50, loss: 345.788, epoch time: 2.377\n",
      "epoch: 100, loss: 266.324, epoch time: 2.258\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 3.336\n",
      "epoch: 150, loss: 248.448, epoch time: 2.239\n",
      "epoch: 200, loss: 239.450, epoch time: 2.256\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 3.355\n",
      "epoch: 250, loss: 233.558, epoch time: 2.231\n",
      "epoch: 300, loss: 228.763, epoch time: 2.290\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 3.363\n",
      "epoch: 350, loss: 225.378, epoch time: 2.188\n",
      "epoch: 400, loss: 222.247, epoch time: 2.263\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 3.373\n",
      "Finished training\n",
      "Training with input_seq_len=20, output_seq_len=28\n",
      "epoch: 0, loss: 1321.388, epoch time: 2.172\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 3.612\n",
      "epoch: 50, loss: 402.830, epoch time: 2.309\n",
      "epoch: 100, loss: 297.245, epoch time: 2.229\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 4.119\n",
      "epoch: 150, loss: 272.944, epoch time: 2.348\n",
      "epoch: 200, loss: 261.768, epoch time: 2.240\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 4.126\n",
      "epoch: 250, loss: 255.435, epoch time: 2.243\n",
      "epoch: 300, loss: 249.740, epoch time: 2.320\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 4.133\n",
      "epoch: 350, loss: 245.820, epoch time: 2.223\n",
      "epoch: 400, loss: 242.631, epoch time: 2.260\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 4.162\n",
      "Finished training\n",
      "Training with input_seq_len=20, output_seq_len=36\n",
      "epoch: 0, loss: 1573.417, epoch time: 2.153\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 4.308\n",
      "epoch: 50, loss: 464.719, epoch time: 2.315\n",
      "epoch: 100, loss: 328.576, epoch time: 2.295\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 4.901\n",
      "epoch: 150, loss: 297.649, epoch time: 2.256\n",
      "epoch: 200, loss: 282.982, epoch time: 2.171\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 4.935\n",
      "epoch: 250, loss: 274.625, epoch time: 2.279\n",
      "epoch: 300, loss: 267.932, epoch time: 2.375\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 4.937\n",
      "epoch: 350, loss: 263.345, epoch time: 2.184\n",
      "epoch: 400, loss: 259.772, epoch time: 2.181\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 4.959\n",
      "Finished training\n",
      "Training with input_seq_len=20, output_seq_len=44\n",
      "epoch: 0, loss: 1816.236, epoch time: 2.318\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 4.864\n",
      "epoch: 50, loss: 545.573, epoch time: 2.291\n",
      "epoch: 100, loss: 366.235, epoch time: 2.292\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 5.660\n",
      "epoch: 150, loss: 326.642, epoch time: 2.192\n",
      "epoch: 200, loss: 306.819, epoch time: 2.194\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 5.717\n",
      "epoch: 250, loss: 296.486, epoch time: 2.312\n",
      "epoch: 300, loss: 289.291, epoch time: 2.289\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 5.690\n",
      "epoch: 350, loss: 280.206, epoch time: 2.269\n",
      "epoch: 400, loss: 278.395, epoch time: 2.189\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 5.708\n",
      "Finished training\n",
      "Training with input_seq_len=28, output_seq_len=12\n",
      "epoch: 0, loss: 758.031, epoch time: 2.930\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 2.180\n",
      "epoch: 50, loss: 274.872, epoch time: 2.952\n",
      "epoch: 100, loss: 225.587, epoch time: 3.049\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 2.620\n",
      "epoch: 150, loss: 209.500, epoch time: 2.935\n",
      "epoch: 200, loss: 196.986, epoch time: 3.011\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 2.608\n",
      "epoch: 250, loss: 187.705, epoch time: 2.959\n",
      "epoch: 300, loss: 180.346, epoch time: 2.966\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 2.602\n",
      "epoch: 350, loss: 173.536, epoch time: 2.957\n",
      "epoch: 400, loss: 167.757, epoch time: 3.018\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 2.615\n",
      "Finished training\n",
      "Training with input_seq_len=28, output_seq_len=20\n",
      "epoch: 0, loss: 1039.993, epoch time: 2.954\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 2.905\n",
      "epoch: 50, loss: 321.729, epoch time: 3.021\n",
      "epoch: 100, loss: 256.331, epoch time: 3.009\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 3.434\n",
      "epoch: 150, loss: 240.386, epoch time: 3.013\n",
      "epoch: 200, loss: 232.176, epoch time: 3.059\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 3.458\n",
      "epoch: 250, loss: 226.005, epoch time: 2.999\n",
      "epoch: 300, loss: 221.292, epoch time: 2.947\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 3.447\n",
      "epoch: 350, loss: 217.395, epoch time: 2.917\n",
      "epoch: 400, loss: 213.545, epoch time: 2.971\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 3.456\n",
      "Finished training\n",
      "Training with input_seq_len=28, output_seq_len=28\n",
      "epoch: 0, loss: 1301.344, epoch time: 2.892\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 3.603\n",
      "epoch: 50, loss: 360.715, epoch time: 2.812\n",
      "epoch: 100, loss: 280.485, epoch time: 2.887\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 4.207\n",
      "epoch: 150, loss: 261.460, epoch time: 2.835\n",
      "epoch: 200, loss: 251.935, epoch time: 2.876\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 4.217\n",
      "epoch: 250, loss: 245.775, epoch time: 2.857\n",
      "epoch: 300, loss: 240.279, epoch time: 2.864\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 4.214\n",
      "epoch: 350, loss: 236.838, epoch time: 2.918\n",
      "epoch: 400, loss: 233.475, epoch time: 2.782\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 4.234\n",
      "Finished training\n",
      "Training with input_seq_len=28, output_seq_len=36\n",
      "epoch: 0, loss: 1563.772, epoch time: 2.728\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 4.272\n",
      "epoch: 50, loss: 415.345, epoch time: 2.770\n",
      "epoch: 100, loss: 307.879, epoch time: 2.842\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 4.960\n",
      "epoch: 150, loss: 284.141, epoch time: 2.955\n",
      "epoch: 200, loss: 270.524, epoch time: 2.957\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 4.925\n",
      "epoch: 250, loss: 262.374, epoch time: 2.849\n",
      "epoch: 300, loss: 257.917, epoch time: 2.799\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 4.910\n",
      "epoch: 350, loss: 252.205, epoch time: 2.840\n",
      "epoch: 400, loss: 248.656, epoch time: 2.908\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 4.945\n",
      "Finished training\n",
      "Training with input_seq_len=28, output_seq_len=44\n",
      "epoch: 0, loss: 1792.950, epoch time: 2.717\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 4.906\n",
      "epoch: 50, loss: 450.793, epoch time: 2.687\n",
      "epoch: 100, loss: 331.056, epoch time: 2.704\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 5.705\n",
      "epoch: 150, loss: 302.730, epoch time: 2.763\n",
      "epoch: 200, loss: 286.950, epoch time: 2.658\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 5.673\n",
      "epoch: 250, loss: 277.835, epoch time: 2.747\n",
      "epoch: 300, loss: 271.174, epoch time: 2.730\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 5.686\n",
      "epoch: 350, loss: 265.485, epoch time: 2.927\n",
      "epoch: 400, loss: 264.126, epoch time: 2.978\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 5.719\n",
      "Finished training\n",
      "Training with input_seq_len=36, output_seq_len=12\n",
      "epoch: 0, loss: 752.989, epoch time: 3.208\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 2.185\n",
      "epoch: 50, loss: 271.055, epoch time: 3.352\n",
      "epoch: 100, loss: 221.182, epoch time: 3.391\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 2.627\n",
      "epoch: 150, loss: 203.107, epoch time: 3.328\n",
      "epoch: 200, loss: 188.987, epoch time: 3.395\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 2.616\n",
      "epoch: 250, loss: 178.366, epoch time: 3.387\n",
      "epoch: 300, loss: 169.325, epoch time: 3.398\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 2.629\n",
      "epoch: 350, loss: 160.510, epoch time: 3.479\n",
      "epoch: 400, loss: 151.521, epoch time: 3.339\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 2.617\n",
      "Finished training\n",
      "Training with input_seq_len=36, output_seq_len=20\n",
      "epoch: 0, loss: 1032.374, epoch time: 3.283\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 2.882\n",
      "epoch: 50, loss: 306.994, epoch time: 3.298\n",
      "epoch: 100, loss: 249.979, epoch time: 3.297\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 3.474\n",
      "epoch: 150, loss: 235.539, epoch time: 3.396\n",
      "epoch: 200, loss: 226.729, epoch time: 3.391\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 3.465\n",
      "epoch: 250, loss: 219.713, epoch time: 3.441\n",
      "epoch: 300, loss: 213.981, epoch time: 3.353\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 3.472\n",
      "epoch: 350, loss: 209.641, epoch time: 3.428\n",
      "epoch: 400, loss: 205.918, epoch time: 3.465\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 3.453\n",
      "Finished training\n",
      "Training with input_seq_len=36, output_seq_len=28\n",
      "epoch: 0, loss: 1299.714, epoch time: 3.105\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 3.574\n",
      "epoch: 50, loss: 377.380, epoch time: 3.439\n",
      "epoch: 100, loss: 279.276, epoch time: 3.340\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 4.385\n",
      "epoch: 150, loss: 261.904, epoch time: 3.325\n",
      "epoch: 200, loss: 251.234, epoch time: 3.350\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 4.378\n",
      "epoch: 250, loss: 242.737, epoch time: 3.320\n",
      "epoch: 300, loss: 238.208, epoch time: 3.417\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 4.404\n",
      "epoch: 350, loss: 233.377, epoch time: 3.399\n",
      "epoch: 400, loss: 231.647, epoch time: 3.384\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 4.397\n",
      "Finished training\n",
      "Training with input_seq_len=36, output_seq_len=36\n",
      "epoch: 0, loss: 1540.463, epoch time: 3.125\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 4.251\n",
      "epoch: 50, loss: 394.922, epoch time: 3.377\n",
      "epoch: 100, loss: 299.123, epoch time: 3.524\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 4.973\n",
      "epoch: 150, loss: 276.799, epoch time: 3.390\n",
      "epoch: 200, loss: 264.665, epoch time: 3.416\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 4.922\n",
      "epoch: 250, loss: 256.901, epoch time: 3.367\n",
      "epoch: 300, loss: 251.515, epoch time: 3.296\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 4.967\n",
      "epoch: 350, loss: 247.486, epoch time: 3.381\n",
      "epoch: 400, loss: 243.935, epoch time: 3.454\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 4.954\n",
      "Finished training\n",
      "Training with input_seq_len=36, output_seq_len=44\n",
      "epoch: 0, loss: 1779.725, epoch time: 3.188\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 4.841\n",
      "epoch: 50, loss: 413.686, epoch time: 3.464\n",
      "epoch: 100, loss: 319.093, epoch time: 3.380\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 5.729\n",
      "epoch: 150, loss: 292.451, epoch time: 3.385\n",
      "epoch: 200, loss: 280.761, epoch time: 3.499\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 5.701\n",
      "epoch: 250, loss: 269.997, epoch time: 3.443\n",
      "epoch: 300, loss: 264.123, epoch time: 3.420\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 5.701\n",
      "epoch: 350, loss: 260.876, epoch time: 3.464\n",
      "epoch: 400, loss: 254.738, epoch time: 3.451\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 5.702\n",
      "Finished training\n",
      "Training with input_seq_len=44, output_seq_len=12\n",
      "epoch: 0, loss: 744.038, epoch time: 3.823\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 2.168\n",
      "epoch: 50, loss: 268.305, epoch time: 3.965\n",
      "epoch: 100, loss: 219.627, epoch time: 3.954\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 2.710\n",
      "epoch: 150, loss: 200.568, epoch time: 4.032\n",
      "epoch: 200, loss: 188.097, epoch time: 3.940\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 2.693\n",
      "epoch: 250, loss: 177.984, epoch time: 4.022\n",
      "epoch: 300, loss: 170.235, epoch time: 4.158\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 2.689\n",
      "epoch: 350, loss: 163.232, epoch time: 4.050\n",
      "epoch: 400, loss: 155.575, epoch time: 4.051\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 2.701\n",
      "Finished training\n",
      "Training with input_seq_len=44, output_seq_len=20\n",
      "epoch: 0, loss: 1023.509, epoch time: 3.924\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 2.906\n",
      "epoch: 50, loss: 306.638, epoch time: 3.965\n",
      "epoch: 100, loss: 249.156, epoch time: 3.939\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 3.508\n",
      "epoch: 150, loss: 235.916, epoch time: 3.997\n",
      "epoch: 200, loss: 226.797, epoch time: 4.078\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 3.508\n",
      "epoch: 250, loss: 217.963, epoch time: 3.959\n",
      "epoch: 300, loss: 211.645, epoch time: 3.913\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 3.519\n",
      "epoch: 350, loss: 207.691, epoch time: 3.989\n",
      "epoch: 400, loss: 201.729, epoch time: 3.891\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 3.518\n",
      "Finished training\n",
      "Training with input_seq_len=44, output_seq_len=28\n",
      "epoch: 0, loss: 1280.122, epoch time: 3.871\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 3.583\n",
      "epoch: 50, loss: 343.442, epoch time: 3.932\n",
      "epoch: 100, loss: 272.629, epoch time: 4.035\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 4.273\n",
      "epoch: 150, loss: 254.546, epoch time: 4.194\n",
      "epoch: 200, loss: 244.616, epoch time: 4.089\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 4.240\n",
      "epoch: 250, loss: 238.950, epoch time: 3.974\n",
      "epoch: 300, loss: 232.487, epoch time: 4.050\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 4.271\n",
      "epoch: 350, loss: 229.057, epoch time: 4.021\n",
      "epoch: 400, loss: 224.964, epoch time: 4.039\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 4.241\n",
      "Finished training\n",
      "Training with input_seq_len=44, output_seq_len=36\n",
      "epoch: 0, loss: 1523.316, epoch time: 3.739\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 4.233\n",
      "epoch: 50, loss: 370.484, epoch time: 3.976\n",
      "epoch: 100, loss: 292.205, epoch time: 4.038\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 4.969\n",
      "epoch: 150, loss: 271.947, epoch time: 4.058\n",
      "epoch: 200, loss: 259.977, epoch time: 4.031\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 4.956\n",
      "epoch: 250, loss: 252.452, epoch time: 3.996\n",
      "epoch: 300, loss: 247.377, epoch time: 4.054\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 4.976\n",
      "epoch: 350, loss: 242.732, epoch time: 3.902\n",
      "epoch: 400, loss: 239.321, epoch time: 3.887\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 5.016\n",
      "Finished training\n",
      "Training with input_seq_len=44, output_seq_len=44\n",
      "epoch: 0, loss: 1755.601, epoch time: 3.752\n",
      "++++++++++++++++\n",
      "Eval epoch: 0, Test set mean ADE 4.791\n",
      "epoch: 50, loss: 405.952, epoch time: 3.929\n",
      "epoch: 100, loss: 314.244, epoch time: 3.932\n",
      "++++++++++++++++\n",
      "Eval epoch: 100, Test set mean ADE 5.540\n",
      "epoch: 150, loss: 289.569, epoch time: 4.007\n",
      "epoch: 200, loss: 275.615, epoch time: 3.908\n",
      "++++++++++++++++\n",
      "Eval epoch: 200, Test set mean ADE 5.587\n",
      "epoch: 250, loss: 266.879, epoch time: 3.980\n",
      "epoch: 300, loss: 260.538, epoch time: 3.953\n",
      "++++++++++++++++\n",
      "Eval epoch: 300, Test set mean ADE 5.610\n",
      "epoch: 350, loss: 255.799, epoch time: 4.078\n",
      "epoch: 400, loss: 251.754, epoch time: 4.035\n",
      "++++++++++++++++\n",
      "Eval epoch: 400, Test set mean ADE 5.636\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "inp_lens = range(12, 49, 8)\n",
    "out_lens = inp_lens\n",
    "\n",
    "ADEs = train_eval.grid_input_output(lstm.LSTMdense, all_df, inp_lens, out_lens, inp_labels, out_labels, 'Prediction/traj_models/RED/', 401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADEs = ADEs.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2193172 , 2.94573975, 3.66684103, 4.36968851, 4.93245792],\n",
       "       [2.193115  , 2.93659759, 3.61216402, 4.30841875, 4.86428928],\n",
       "       [2.17989755, 2.90543628, 3.60302877, 4.27222824, 4.90603304],\n",
       "       [2.18515611, 2.88209367, 3.57404041, 4.25071716, 4.84111214],\n",
       "       [2.16800404, 2.9057312 , 3.58273959, 4.23318243, 4.79080868]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADEs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>20</th>\n",
       "      <th>28</th>\n",
       "      <th>36</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.219317</td>\n",
       "      <td>2.945740</td>\n",
       "      <td>3.666841</td>\n",
       "      <td>4.369689</td>\n",
       "      <td>4.932458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.193115</td>\n",
       "      <td>2.936598</td>\n",
       "      <td>3.612164</td>\n",
       "      <td>4.308419</td>\n",
       "      <td>4.864289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.179898</td>\n",
       "      <td>2.905436</td>\n",
       "      <td>3.603029</td>\n",
       "      <td>4.272228</td>\n",
       "      <td>4.906033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.185156</td>\n",
       "      <td>2.882094</td>\n",
       "      <td>3.574040</td>\n",
       "      <td>4.250717</td>\n",
       "      <td>4.841112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.168004</td>\n",
       "      <td>2.905731</td>\n",
       "      <td>3.582740</td>\n",
       "      <td>4.233182</td>\n",
       "      <td>4.790809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          12        20        28        36        44\n",
       "12  2.219317  2.945740  3.666841  4.369689  4.932458\n",
       "20  2.193115  2.936598  3.612164  4.308419  4.864289\n",
       "28  2.179898  2.905436  3.603029  4.272228  4.906033\n",
       "36  2.185156  2.882094  3.574040  4.250717  4.841112\n",
       "44  2.168004  2.905731  3.582740  4.233182  4.790809"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'input length')"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolor(ADEs)\n",
    "plt.yticks(np.arange(0.5, len(ADEs.index), 1)[::-1], ADEs.columns)\n",
    "plt.xticks(np.arange(0.5, len(ADEs.columns), 1), ADEs.index)\n",
    "plt.xlabel('output length')\n",
    "plt.ylabel('input length',rotation=30,labelpad=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>20</th>\n",
       "      <th>28</th>\n",
       "      <th>36</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.219317</td>\n",
       "      <td>2.945740</td>\n",
       "      <td>3.666841</td>\n",
       "      <td>4.369689</td>\n",
       "      <td>4.932458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.193115</td>\n",
       "      <td>2.936598</td>\n",
       "      <td>3.612164</td>\n",
       "      <td>4.308419</td>\n",
       "      <td>4.864289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.179898</td>\n",
       "      <td>2.905436</td>\n",
       "      <td>3.603029</td>\n",
       "      <td>4.272228</td>\n",
       "      <td>4.906033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.185156</td>\n",
       "      <td>2.882094</td>\n",
       "      <td>3.574040</td>\n",
       "      <td>4.250717</td>\n",
       "      <td>4.841112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.168004</td>\n",
       "      <td>2.905731</td>\n",
       "      <td>3.582740</td>\n",
       "      <td>4.233182</td>\n",
       "      <td>4.790809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          12        20        28        36        44\n",
       "12  2.219317  2.945740  3.666841  4.369689  4.932458\n",
       "20  2.193115  2.936598  3.612164  4.308419  4.864289\n",
       "28  2.179898  2.905436  3.603029  4.272228  4.906033\n",
       "36  2.185156  2.882094  3.574040  4.250717  4.841112\n",
       "44  2.168004  2.905731  3.582740  4.233182  4.790809"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Prediction.LSTM_predict as lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMdense(\n",
       "  (LSTM): LSTM(2, 256, num_layers=2)\n",
       "  (dense): Linear(in_features=256, out_features=48, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++\n",
      "Test set mean ADE 3.694\n"
     ]
    }
   ],
   "source": [
    "total_ADE = 0\n",
    "count = 0\n",
    "device = torch.device('cuda')\n",
    "for (x, y) in train_dataloader:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = net(x)\n",
    "\n",
    "    total_ADE += lstm.calc_ADE(pred, y)\n",
    "    count += 1\n",
    "\n",
    "print(\"++++++++++++++++\")\n",
    "print(f\"Test set mean ADE {total_ADE/count:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.output_seq_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = iter(train_dataloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Pogona_Pursuit/Arena/experiments/initial_20200727T071226',\n",
       " '../Pogona_Pursuit/Arena/experiments/initial_20200727T073708',\n",
       " '../Pogona_Pursuit/Arena/experiments/bug_size_20200727T080358',\n",
       " '../Pogona_Pursuit/Arena/experiments/fps_check_20200727T083454',\n",
       " '../Pogona_Pursuit/Arena/experiments/test_20200727T100404',\n",
       " '../Pogona_Pursuit/Arena/experiments/test_fps_20200727T102701',\n",
       " '../Pogona_Pursuit/Arena/experiments/fps_check_20200727T105124',\n",
       " '../Pogona_Pursuit/Arena/experiments/fps_check_20200727T110833',\n",
       " '../Pogona_Pursuit/Arena/experiments/delete_20200727T161744',\n",
       " '../Pogona_Pursuit/Arena/experiments/initial_20200729T071920',\n",
       " '../Pogona_Pursuit/Arena/experiments/worm_20200729T074653',\n",
       " '../Pogona_Pursuit/Arena/experiments/worm_20200729T075548',\n",
       " '../Pogona_Pursuit/Arena/experiments/cockroach_20200729T084031',\n",
       " '../Pogona_Pursuit/Arena/experiments/vegetables_20200729T084925',\n",
       " '../Pogona_Pursuit/Arena/experiments/worm_20200729T090421',\n",
       " '../Pogona_Pursuit/Arena/experiments/vegetables_20200729T092014',\n",
       " '../Pogona_Pursuit/Arena/experiments/fast_cockroach_20200729T094929',\n",
       " '../Pogona_Pursuit/Arena/experiments/cockroach_20200729T101509',\n",
       " '../Pogona_Pursuit/Arena/experiments/worm_20200729T103122',\n",
       " '../Pogona_Pursuit/Arena/experiments/fast_cockroach_20200729T105342',\n",
       " '../Pogona_Pursuit/Arena/experiments/vegetables_20200729T111144',\n",
       " '../Pogona_Pursuit/Arena/experiments/fast_cockroach_20200729T093829',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200730T115819',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200730T120805',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200730T120821',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200730T113527',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200730T124208',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_worm_20200730T125503',\n",
       " '../Pogona_Pursuit/Arena/experiments/fast_cockroach_line_20200730T131606',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200730T133208',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200803T075244',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200803T075733',\n",
       " '../Pogona_Pursuit/Arena/experiments/line_20200803T081041',\n",
       " '../Pogona_Pursuit/Arena/experiments/line_20200803T081429',\n",
       " '../Pogona_Pursuit/Arena/experiments/line_20200803T081735',\n",
       " '../Pogona_Pursuit/Arena/experiments/line_20200803T082002',\n",
       " '../Pogona_Pursuit/Arena/experiments/fast_line_20200803T082414',\n",
       " '../Pogona_Pursuit/Arena/experiments/fast_line_20200803T082724',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200803T084227',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200803T084529',\n",
       " '../Pogona_Pursuit/Arena/experiments/fast_cockroach_20200803T085738',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200803T090234',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200803T090615',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200803T091639',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200803T092248',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200803T093051',\n",
       " '../Pogona_Pursuit/Arena/experiments/line_20200803T094928',\n",
       " '../Pogona_Pursuit/Arena/experiments/line_20200803T095401',\n",
       " '../Pogona_Pursuit/Arena/experiments/line_20200803T101641',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200803T113121',\n",
       " '../Pogona_Pursuit/Arena/experiments/line_20200803T114942',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200803T115839',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200803T120911',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200803T121730',\n",
       " '../Pogona_Pursuit/Arena/experiments/line_20200803T122506',\n",
       " '../Pogona_Pursuit/Arena/experiments/test-no-streaming-4_20200810T115814',\n",
       " '../Pogona_Pursuit/Arena/experiments/test-no-streaming-rt-only_20200810T120030',\n",
       " '../Pogona_Pursuit/Arena/experiments/untitled.txt',\n",
       " '../Pogona_Pursuit/Arena/experiments/fast_20200819T085841',\n",
       " '../Pogona_Pursuit/Arena/experiments/fast_20200819T093920',\n",
       " '../Pogona_Pursuit/Arena/experiments/circle_20200819T102503',\n",
       " '../Pogona_Pursuit/Arena/experiments/worm_20200819T103031',\n",
       " '../Pogona_Pursuit/Arena/experiments/worm_20200819T104454',\n",
       " '../Pogona_Pursuit/Arena/experiments/worm_20200819T105608',\n",
       " '../Pogona_Pursuit/Arena/experiments/red_beetle_20200824T073952',\n",
       " '../Pogona_Pursuit/Arena/experiments/red_beetle_20200824T074504',\n",
       " '../Pogona_Pursuit/Arena/experiments/red_beetle_20200824T075143',\n",
       " '../Pogona_Pursuit/Arena/experiments/red_beetle_20200824T075929',\n",
       " '../Pogona_Pursuit/Arena/experiments/red_beetle_20200824T081122',\n",
       " '../Pogona_Pursuit/Arena/experiments/red_beetle_20200824T082352',\n",
       " '../Pogona_Pursuit/Arena/experiments/cockroach_20200824T083436',\n",
       " '../Pogona_Pursuit/Arena/experiments/cockroach_20200824T105816']"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('../Pogona_Pursuit/Arena/experiments/*')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
